{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16935c20-ea1e-41ee-980f-5df3013f34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /hdd/yuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7163c5dd-a2e9-49f3-8f95-c1bb31e2d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapes\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pulse2percept as p2p\n",
    "import skimage\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "import math\n",
    "import string\n",
    "from statistics import mean\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm \n",
    "import pingouin as pg\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import statsmodels\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.diagnostic import normal_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393e23f-96cf-496b-aa4f-521180cd6349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_length(curve):\n",
    "    return np.sum(np.sqrt(np.sum((curve[:-1] - curve[1:])**2,axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb5ea99-9188-4c9e-9234-508bf907dcaa",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5bff5-54e8-4368-ac3b-52d3edf4d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate shapes \n",
    "data = shapes.load_shapes(\"/home/yuchen/shapes/data/shapes.h5\", subjects=['12-005','51-009','52-001'],stim_class=None)\n",
    "\n",
    "result = pd.DataFrame({})\n",
    "for i in range(len(data)):\n",
    "    label_img = skimage.measure.label(data['image'][i]>0)\n",
    "    regions = regionprops(label_img)\n",
    "    props = regionprops_table(label_img, properties=('centroid',\n",
    "                                                     'orientation',\n",
    "                                                     'major_axis_length',\n",
    "                                                     'minor_axis_length',\n",
    "                                                     'area',\n",
    "                                                    'eccentricity',\n",
    "                                                    'perimeter'))\n",
    "    df = pd.DataFrame(props).astype('object')\n",
    "    df.at[0,'centroid-0'] = df.iloc[:, 0].tolist()  # store centroid-x\n",
    "    df.at[0,'centroid-1'] = df.iloc[:, 1].tolist()  # store centroid-y\n",
    "    df.at[0,'orientation'] = df.iloc[:, 2].tolist()  # store orientation\n",
    "    df.at[0,'major_axis_length'] = df.iloc[:, 3].tolist()  # major\n",
    "    df.at[0,'minor_axis_length'] = df.iloc[:, 4].tolist()  # minor\n",
    "    df.at[0,'area'] = df.iloc[:, 5].tolist()  # area\n",
    "    df.at[0,'eccentricity'] = df.iloc[:, 6].tolist()  \n",
    "    df.at[0,'perimeter'] = df.iloc[:, 7].tolist()  \n",
    "    result = pd.concat([result, df.iloc[:1,:]],axis=0)\n",
    "\n",
    "result = result.rename(columns={\"area\":\"size\", \"orientation\":\"orientation_new\", \"eccentricity\":\"eccentricity_new\" })\n",
    "data = pd.concat([data,result.reset_index(drop=True)],axis=1)\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72480554",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be5b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "misct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "double = data[data.electrode2 != str()].reset_index(drop=True)\n",
    "s4 = double[double.subject == '52-001'].reset_index(drop=True)\n",
    "stim_class = []\n",
    "\n",
    "for i in range(len(s4)):\n",
    "    if 'VCF1' in s4.filename[i]:\n",
    "        if s4.iloc[i]['stim_class'] == 'SpatialSummation': misct +=1 \n",
    "        stim_class.append('MultiElectrode')\n",
    "    else:\n",
    "        if s4.iloc[i]['stim_class'] == 'MultiElectrode': misct +=1 \n",
    "        stim_class.append('SpatialSummation')\n",
    "s4['stim_class'] = stim_class        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e01ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "double = data[data.electrode2 != str()].reset_index(drop=True)\n",
    "s3 = double[double.subject == '51-009'].reset_index(drop=True)\n",
    "stim_class = []\n",
    "for i in range(len(s3)):\n",
    "    if 'VCF1' in s3.filename[i]:\n",
    "        if s3.iloc[i]['stim_class'] == 'SpatialSummation': misct +=1\n",
    "        stim_class.append('MultiElectrode')\n",
    "    else:\n",
    "        if s3.iloc[i]['stim_class'] == 'MultiElectrode': misct +=1 \n",
    "        stim_class.append('SpatialSummation')\n",
    "s3['stim_class'] = stim_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc396f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "double = data[data.electrode2 != str()].reset_index(drop=True)\n",
    "s2 = double[double.subject == '12-005'].reset_index(drop=True)\n",
    "stim_class = []\n",
    "\n",
    "for i in range(len(s2)):\n",
    "    if 'set A' in s2.filename[i] or 'set C' in s2.filename[i] :\n",
    "        if s2.iloc[i]['stim_class'] == 'SpatialSummation': misct +=1 \n",
    "        stim_class.append('MultiElectrode')\n",
    "    else:\n",
    "        if s2.iloc[i]['stim_class'] == 'MultiElectrode': misct +=1 \n",
    "        stim_class.append('SpatialSummation')\n",
    "s2['stim_class'] = stim_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3466aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "misct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "double = data[data.electrode2 != str()].reset_index(drop=True)\n",
    "double_recreated = pd.concat([s2,s3,s4]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(double[double.stim_class == 'SpatialSummation']))\n",
    "print(len(double_recreated[double_recreated.stim_class == 'SpatialSummation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b781788",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.area >= 10].reset_index(drop=True)\n",
    "double_recreated = double_recreated[double_recreated.area >= 10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1166092",
   "metadata": {},
   "outputs": [],
   "source": [
    "single.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "single = data[data.electrode2 == str()]\n",
    "print(len(single[single.num_regions==1])/len(single))\n",
    "print(len(single[single.num_regions==2])/len(single))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/yuchen/shapes/shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc0ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distances import dist_across_along, dist_perpendicular_tangential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_params = {\n",
    "    '12-005': {\n",
    "        'subject_id': 'S2',\n",
    "        'implant_type_str': 'ArgusII',\n",
    "        'implant_x': -1896,\n",
    "        'implant_y': -542,\n",
    "        'implant_rot': -44,\n",
    "        'loc_od_x': 15.8,\n",
    "        'loc_od_y': 1.4,\n",
    "        'xmin': -30,\n",
    "        'xmax': 30,\n",
    "        'ymin': -22.5,\n",
    "        'ymax': 22.5\n",
    "    },\n",
    "    '51-009': {\n",
    "        'subject_id': 'S3',\n",
    "        'implant_type_str': 'ArgusII',\n",
    "        'implant_x': -1203,\n",
    "        'implant_y': 280,\n",
    "        'implant_rot': -35,\n",
    "        'loc_od_x': 15.4,\n",
    "        'loc_od_y': 1.57,\n",
    "        'xmin': -32.5,\n",
    "        'xmax': 32.5,\n",
    "        'ymin': -24.4,\n",
    "        'ymax': 24.4\n",
    "    },\n",
    "    '52-001': {\n",
    "        'subject_id': 'S4',\n",
    "        'implant_type_str': 'ArgusII',\n",
    "        'implant_x': -1945,\n",
    "        'implant_y': 469,\n",
    "        'implant_rot': -34,\n",
    "        'loc_od_x': 15.8,\n",
    "        'loc_od_y': 1.51,\n",
    "        'xmin': -32,\n",
    "        'xmax': 32,\n",
    "        'ymin': -24,\n",
    "        'ymax': 24\n",
    "    }}\n",
    "\n",
    "models = {\n",
    "    '12-005': p2p.models.AxonMapModel(loc_od=(subj_params['12-005']['loc_od_x'], subj_params['12-005']['loc_od_y'])),\n",
    "    '51-009': p2p.models.AxonMapModel(loc_od=(subj_params['51-009']['loc_od_x'], subj_params['51-009']['loc_od_y'])),\n",
    "    '52-001': p2p.models.AxonMapModel(loc_od=(subj_params['52-001']['loc_od_x'], subj_params['52-001']['loc_od_y'])),\n",
    "}\n",
    "implants = {\n",
    "    '12-005': p2p.implants.ArgusII(x=subj_params['12-005']['implant_x'], y=subj_params['12-005']['implant_y'], \n",
    "                                   rot=subj_params['12-005']['implant_rot']),\n",
    "    '51-009': p2p.implants.ArgusII(x=subj_params['51-009']['implant_x'], y=subj_params['51-009']['implant_y'], \n",
    "                                   rot=subj_params['51-009']['implant_rot']),\n",
    "    '52-001': p2p.implants.ArgusII(x=subj_params['52-001']['implant_x'], y=subj_params['52-001']['implant_y'], \n",
    "                                   rot=subj_params['52-001']['implant_rot'])\n",
    "}\n",
    "\n",
    "def too_close(subject, delta_y=200, delta_rot=10):\n",
    "    \"\"\"Which electrodes would fall on the other side of the raphe if y or rot were a little off?\"\"\"\n",
    "    # y value within abs(delta_y)? This means shifting up/down will push them\n",
    "    # on the other side:\n",
    "    implant = implants[subject]\n",
    "    electrodes = set()\n",
    "    if delta_y > 0:\n",
    "        electrodes = set([n for n, e in implant.electrodes.items() if np.abs(e.y) < delta_y])\n",
    "    if delta_rot > 0:\n",
    "        for rot in [-delta_rot, delta_rot]:\n",
    "            new_implant = p2p.implants.ArgusII(x=subj_params[subject]['implant_x'], \n",
    "                                            y=subj_params[subject]['implant_y'], \n",
    "                                            rot=subj_params[subject]['implant_rot'] + rot)\n",
    "            # if signbit is true, the y value changed sign by rotating the implant:\n",
    "            changed = set([n for n, e in new_implant.electrodes.items() if np.signbit(e.y * implant[n].y)])\n",
    "            electrodes = electrodes.union(changed)\n",
    "    return list(electrodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7368c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9bcd0-ab17-4ad3-bd31-e4d4866b7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_copy.copy()\n",
    "\n",
    "# data_double = data[(data['electrode2'] != str())].reset_index(drop=True)\n",
    "data_double = double_recreated.copy()\n",
    "data_single = data[(data['electrode2'] == str())].reset_index(drop=True)\n",
    "data_single['stim_class'] ='SingleElectrode'\n",
    "df = data_single[['subject', 'electrode1', 'freq', 'amp1']].drop_duplicates().reset_index(drop=True)\n",
    "mo = 0\n",
    "de = 0\n",
    "lst = []\n",
    "lst_size = []\n",
    "lst_major = []\n",
    "lst_minor = []\n",
    "lst_eccentricity = []\n",
    "lst_orientation = []\n",
    "lst_perimeter = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df_temp = data_single[(data_single['subject'] == df.subject[i]) & (data_single['electrode1'] == df.electrode1[i]) & (data_single['freq'] == df.freq[i]) & (data_single['amp1'] == df.amp1[i])].reset_index(drop=True)\n",
    "    ratio = len(df_temp[df_temp['num_regions']>1]) /len(df_temp)\n",
    "    \n",
    "    for row in range(len(df_temp)):\n",
    "        df_temp['size'][row] = sum(df_temp['size'][row])\n",
    "        df_temp['major_axis_length'][row] = sum(df_temp['major_axis_length'][row])\n",
    "        df_temp['minor_axis_length'][row] = sum(df_temp['minor_axis_length'][row])\n",
    "        df_temp['perimeter'][row] = sum(df_temp['perimeter'][row])\n",
    "        df_temp['orientation_new'][row] = sum(df_temp['orientation_new'][row])\n",
    "        \n",
    "    \n",
    "    count_length = len(df_temp)\n",
    "    \n",
    "    lst_size.append(df_temp['size'].sum()/count_length)\n",
    "    lst_major.append(df_temp['major_axis_length'].sum()/count_length)\n",
    "    lst_minor.append(df_temp['minor_axis_length'].sum()/count_length)\n",
    "    lst_perimeter.append(df_temp['perimeter'].sum()/count_length)\n",
    "    lst_orientation.append(df_temp['orientation_new'].sum()/count_length)\n",
    "    \n",
    "        \n",
    "df['avg_size'] = lst_size\n",
    "df['avg_major'] = lst_major\n",
    "df['avg_minor'] = lst_minor\n",
    "df['avg_perimeter'] = lst_perimeter\n",
    "df['avg_orientation'] = lst_orientation\n",
    "\n",
    "\n",
    "data_single = df.copy()\n",
    "\n",
    "subject = ['12-005', '51-009', '52-001']\n",
    "df = pd.DataFrame({})\n",
    "\n",
    "for subj in subject:\n",
    "    lst_e = []\n",
    "    lst_dtf = []\n",
    "    \n",
    "    s2 = shapes.subject_params[subj]\n",
    "    implant,model = shapes.model_from_params(s2)\n",
    "    for i in string.ascii_uppercase[0:6]: \n",
    "        for j in range(1,11):\n",
    "            electrode = i + str(j)\n",
    "            lst_e.append(electrode)\n",
    "            lst_dtf.append(math.sqrt(implant[electrode].x**2 +implant[electrode].y**2 ))\n",
    "            \n",
    "    df_o = pd.DataFrame(lst_e, columns=['electrode1'])\n",
    "    df_o['distance_to_fovea'] = lst_dtf\n",
    "    \n",
    "    if subj == '12-005':\n",
    "        lst_d = [0,0,0,2,7,7,0,0,5,0,\n",
    "                0,0,4,11,13,15,15,3,7,4,\n",
    "                0,0,15,16,17,17,19,16,9,4,\n",
    "                0,0,16,19,15,17,22,25,13,10,\n",
    "                0,0,8,15,14,13,17,23,14,2,\n",
    "                0,0,10,15,13,12,9,11,5]\n",
    "        lst_e = lst_e[:-1]\n",
    "    elif subj == '51-009':\n",
    "        lst_e = ['F1','F2','F3','F4','F5','F6',\n",
    "               'E1','E2','E3','E4','E5','E6',\n",
    "               'D1','D2','D3','D4','D5','D6','D7',\n",
    "               'C1','C2','C3','C4','C5','C6','C7','C8',\n",
    "               'B1','B2','B3','B4','B5','B6','B7','B8','B9','B10', \n",
    "               'A1','A2','A3','A4','A5','A6','A7','A8','A9','A10']\n",
    "        lst_d = [0] * len(lst_e)\n",
    "    else:\n",
    "        lst_e = ['F1','F2','F4','F5','F6','F7','F8','F9','F10',\n",
    "               'E1','E2','E3','E4','E5','E6','E7','E8','E9','E10', \n",
    "               'D1','D2','D3','D4','D5','D6','D7','D8','D9','D10', \n",
    "               'C3','C4','C5','C6','C7','C8','C9','C10', \n",
    "               'B1','B3','B4','B5','B6','B7','B8','B9','B10', \n",
    "               'A1','A2','A3','A4','A5','A6','A7','A8','A9','A10']\n",
    "        lst_d = [0] * len(lst_e)\n",
    "    lst_s = [subj] * len(lst_e)\n",
    "    \n",
    "    df_o = df_o[df_o.electrode1.isin(lst_e)]\n",
    "    df_o['distance_to_implant'] = lst_d\n",
    "    df_o['subject'] = lst_s\n",
    "    df = pd.concat([df, df_o])\n",
    "data_single = data_single.merge(df, how = 'inner', on = ['electrode1','subject'])\n",
    "\n",
    "\n",
    "index_lst = []\n",
    "for i in range(len(data_double)):\n",
    "    if not (data_single[(data_single['subject'] == data_double.subject[i]) & (data_single['electrode1'] == data_double.electrode1[i]) & (data_single['freq'] == data_double.freq[i]) & (data_single['amp1'] == data_double.amp1[i])].empty):\n",
    "        if not (data_single[(data_single['subject'] == data_double.subject[i]) & (data_single['electrode1'] == data_double.electrode2[i]) & (data_single['freq'] == data_double.freq[i]) & (data_single['amp1'] == data_double.amp1[i])].empty):\n",
    "            index_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_residuals(model, features, label):\n",
    "    \"\"\"\n",
    "    Creates predictions on the features with the model and calculates residuals\n",
    "    \"\"\"\n",
    "    predictions = model.predict(features)\n",
    "    df_results = pd.DataFrame({'Actual': label, 'Predicted': predictions})\n",
    "    df_results['Residuals'] = df_results['Actual'] - df_results['Predicted']\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "def normal_errors_assumption(model, features, label, p_value_thresh=0.05):\n",
    "    \"\"\"\n",
    "    Normality: Assumes that the error terms are normally distributed. If they are not,\n",
    "    nonlinear transformations of variables may solve this.\n",
    "               \n",
    "    This assumption being violated primarily causes issues with the confidence intervals\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Calculating residuals for the Anderson-Darling test\n",
    "    df_results = calculate_residuals(model, features, label)\n",
    "    df_results['Residuals'] = model.resid\n",
    "\n",
    "    # Performing the test on the residuals\n",
    "    p_value = normal_ad(df_results['Residuals'])[1]\n",
    "    print('normal_ad', p_value)\n",
    "    \n",
    "    # Plotting the residuals distribution\n",
    "    plt.subplots(figsize=(12, 6))\n",
    "    plt.title('Distribution of Residuals')\n",
    "    sns.distplot(df_results['Residuals'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9517ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {'area':None,\n",
    "          'perimeter':None,\n",
    "           'major':None,\n",
    "           'minor':None,\n",
    "          'orientation': None,\n",
    "          'phos_num': None}\n",
    "\n",
    "fig_qq, axes_qq = plt.subplots(nrows=6, ncols=4, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ba3ff-0ab7-4b9f-9cfa-f206b71ab827",
   "metadata": {},
   "source": [
    "### size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e366d-f336-4ebc-8343-3a6c7e43c046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_AllSub = pd.DataFrame()\n",
    "\n",
    "condition_list = [0]  \n",
    "label_list = ['MultiElectrode']\n",
    "for condition in condition_list:\n",
    "    for label in range(1):\n",
    "        data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "        data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "        lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "        lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        double = []\n",
    "        single_dtf = []\n",
    "        single_dti = []\n",
    "        lst_subject = []\n",
    "        \n",
    "        distance = []\n",
    "        amp = []\n",
    "        freq = []\n",
    "        electrode = []\n",
    "        across = []\n",
    "        along = []\n",
    "        for i in range(len(lst)):\n",
    "            electrode1 = lst.electrode1[i]\n",
    "            electrode2 = lst.electrode2[i]\n",
    "            temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            close_electrode = too_close(temp1.subject[0], delta_y=100, delta_rot=5)\n",
    "            close_electrode = []\n",
    "            \n",
    "            if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "                if electrode1 not in close_electrode and electrode2 not in close_electrode:\n",
    "                    \n",
    "                    count = 0\n",
    "                    for j in range(len(double_temp)):\n",
    "                        count += sum(double_temp['size'][j])\n",
    "                    double.append(count/len(double_temp))\n",
    "                    single_dtf.append((temp1.distance_to_fovea[0] + temp2.distance_to_fovea[0])/2)\n",
    "                    single_dti.append((temp1.distance_to_implant[0] + temp2.distance_to_implant[0])/2)\n",
    "                    lst_subject.append(temp1.subject[0])\n",
    "\n",
    "                    subject = shapes.subject_params[temp1.subject[0]]\n",
    "                    implant,model = shapes.model_from_params(subject)\n",
    "\n",
    "                    arr = dist_across_along([electrode1], [electrode2], implant, model,strategy='radial')\n",
    "                    \n",
    "                    e1_x = implant[electrode1].x\n",
    "                    e1_y = implant[electrode1].y\n",
    "                    e2_x = implant[electrode2].x\n",
    "                    e2_y = implant[electrode2].y\n",
    "\n",
    "                    distance.append(math.sqrt((e1_x - e2_x)**2 + (e1_y - e2_y)**2))\n",
    "                \n",
    "                    across.append(arr[0,1])\n",
    "                    along.append(arr[0,2])\n",
    "\n",
    "                    amp.append(lst.amp1[i])\n",
    "                    freq.append(lst.freq[i])\n",
    "\n",
    "        df_investigate = pd.DataFrame({\n",
    "                                       'double':double, \n",
    "                                       'freq':freq,\n",
    "                                       'amp':amp,\n",
    "                                       'single_dtf':single_dtf,\n",
    "                                       'single_dti':single_dti,\n",
    "            'distance':distance,\n",
    "                                        'across':across,\n",
    "                                        'along':along,\n",
    "                                       'subject':lst_subject\n",
    "                                      })\n",
    "        \n",
    "        df_AllSub = df_investigate.copy()\n",
    "        \n",
    "            \n",
    "        temp = df_investigate[(df_investigate.amp == 2) & (df_investigate.freq == 20) & \n",
    "                              (df_investigate.single_dti == 0) &\n",
    "                              (df_investigate.single_dtf > 2950) & (df_investigate.single_dtf < 3450)]\n",
    "        \n",
    "        temp = temp.groupby(['amp','freq','subject']).mean().reset_index()\n",
    "        df = pd.DataFrame({})\n",
    "        for subj in temp.subject:\n",
    "            df_investigate_temp = df_investigate[df_investigate.subject == subj]\n",
    "            df_investigate_temp['double'] = df_investigate_temp['double'] / temp[temp.subject == subj].iloc[0]['double']\n",
    "            filename = subj + label_list[label]\n",
    "            df_investigate_temp.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')\n",
    "            df = pd.concat([df, df_investigate_temp])\n",
    "        df_investigate = df.copy()\n",
    "        filename = label_list[label]\n",
    "        df_investigate.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58dff51-f090-45ff-afad-f2f72a187bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy = df_investigate.copy()\n",
    "# df_AllSub=df_investigate.copy()\n",
    "\n",
    "# df_s = pd.DataFrame({})\n",
    "# for subj in ['12-005','51-009','52-001','All']:\n",
    "#     if subj=='All':\n",
    "#         df_t = df_AllSub.copy()\n",
    "#     else:   \n",
    "#         df_t = copy[copy.subject == subj]\n",
    "#     df_t['amp'] = (df_t['amp'] - df_t['amp'].mean()) / df_t['amp'].std()\n",
    "#     df_t['single_dti'] = (df_t['single_dti'] - df_t['single_dti'].mean()) / df_t['single_dti'].std()\n",
    "#     df_t['single_dtf'] = (df_t['single_dtf'] - df_t['single_dtf'].mean()) / df_t['single_dtf'].std()\n",
    "#     df_t['across'] = (df_t['across'] - df_t['across'].mean()) / df_t['across'].std()\n",
    "#     df_t['along'] = (df_t['along'] - df_t['along'].mean()) / df_t['along'].std()\n",
    "# #     df_t['distance'] = (df_t['distance'] - df_t['distance'].mean()) / df_t['distance'].std()\n",
    "    \n",
    "#     if subj == 'All':  \n",
    "#         df_AllSub = df_t.copy()\n",
    "#     else:\n",
    "#         df_s = pd.concat([df_s, df_t])\n",
    "#         df_s = df_s.fillna(0)\n",
    "        \n",
    "# df_investigate = df_s.copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d7298",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2.5\n",
    "\n",
    "removed_indices = []\n",
    "total_len = 0\n",
    "copy = df_investigate.copy()\n",
    "df_AllSub = df_investigate.copy()\n",
    "df_s = pd.DataFrame({})\n",
    "for subj in ['12-005','51-009','52-001','All']:\n",
    "    if subj != 'All': df_t = copy[copy.subject == subj].reset_index(drop=True)\n",
    "    else: df_t = copy.copy()\n",
    "    \n",
    "    if subj != '12-005' and subj != 'All': total_len += len(df_t)\n",
    "    \n",
    "    df_t['amp'] = (df_t['amp'] - df_t['amp'].mean()) / df_t['amp'].std()\n",
    "    df_t['single_dti'] = (df_t['single_dti'] - df_t['single_dti'].mean()) / df_t['single_dti'].std()\n",
    "    df_t['single_dtf'] = (df_t['single_dtf'] - df_t['single_dtf'].mean()) / df_t['single_dtf'].std()\n",
    "    \n",
    "    if subj != 'All': \n",
    "        before_filtering = set(df_t.index)\n",
    "        df_t = df_t.fillna(0)\n",
    "        df_t = df_t[(abs(df_t.amp) <threshold) & \n",
    "                    (abs(df_t.single_dti) < threshold) & (abs(df_t.single_dtf) < threshold)]\n",
    "\n",
    "        removed_indices.extend([x + total_len for x in list(before_filtering - set(df_t.index))])\n",
    "        df_s = pd.concat([df_s, df_t])\n",
    "        df_s = df_s.fillna(0)\n",
    "    else: df_AllSub = df_t.copy()\n",
    "        \n",
    "df_investigate = df_s.copy().reset_index(drop=True)\n",
    "df_AllSub = df_AllSub.reset_index(drop=True).drop(removed_indices).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3254a-b459-43f3-8734-e153a788a09c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, axs= plt.subplots(nrows = 4, ncols=5, figsize=(35, 25))\n",
    "# column_lst = ['amp','single_dti', 'single_dtf','across', 'along']\n",
    "# name_lst = ['Amplitude','Electrode-Retina Distance', 'Electrode-Fovea Distance','Between-Axon Distance','Along-Axon Distance']\n",
    "# for dv in range(5):\n",
    "#     reg = LinearRegression().fit(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]], df_AllSub[['double']])\n",
    "#     y_predicted = reg.predict(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     y = df_AllSub[['double']]-y_predicted\n",
    "\n",
    "#     reg = LinearRegression().fit(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]], df_AllSub[column_lst[dv]])\n",
    "#     y_predicted = reg.predict(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     x = df_AllSub[column_lst[dv]]-y_predicted\n",
    "#     df_AllSub['x'] = x\n",
    "#     df_AllSub['y'] = y\n",
    "#     subject = ['12-005','51-009','52-001']\n",
    "#     marker_lst = ['o','s','^']\n",
    "#     color_lst = ['#1E88E5', '#FFC107','#004D40']\n",
    "#     for i in range(len(subject)):\n",
    "#         temp = df_AllSub[df_AllSub.subject == subject[i]]\n",
    "#         axs[0,dv].plot(temp['x'],temp['y'],marker_lst[i], color=color_lst[i],alpha=0.6,markersize=13)\n",
    "#     axs[0,-1].legend(subject, loc='upper right',prop={'size': 20})\n",
    "#     reg = LinearRegression().fit(np.array(x).reshape(-1,1),np.array(y).reshape(-1,1))\n",
    "#     y_pred = reg.predict(np.array(x).reshape(-1,1))\n",
    "#     axs[0,dv].plot(x, y_pred,'-', color=\"black\",linewidth=2)\n",
    "#     axs[0,dv].set(ylim=(-4,6), xlim=(-2,3.5))\n",
    "#     axs[0,0].set( ylabel = 'Area')\n",
    "#     axs[0,dv].tick_params(axis='both',  labelsize=18)\n",
    "    \n",
    "# #     axs[0,dv].get_xaxis().set_visible(False)\n",
    "# #     if dv>0:\n",
    "# #         axs[0,dv].get_yaxis().set_visible(False)\n",
    "        \n",
    "#     axs[0,dv].yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    \n",
    "#     for item in ([axs[0,dv].xaxis.label, axs[0,dv].yaxis.label]):\n",
    "#         item.set_fontsize(30)\n",
    "# # fig.savefig('/home/yuchen/paper/12a. Double-Electrode Area.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857a941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=6, ncols=4, figsize=(20, 30))\n",
    "subject = ['12-005','51-009','52-001']\n",
    "marker_lst = ['o','s','^']\n",
    "color_lst = ['#1E88E5', '#FFC107','#004D40']\n",
    "\n",
    "temp = df_AllSub.copy().reset_index(drop=True)\n",
    "temp = temp.drop(['freq'], axis=1)\n",
    "temp['double'] = (temp['double'])**(1/3)\n",
    "# ====================amp=====================================\n",
    "mdf1 = MixedLM.from_formula('double ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('amp ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[0,0].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[0,0].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "# ======================single_dtf==================================\n",
    "mdf1 = MixedLM.from_formula('double ~ amp + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('single_dtf ~ amp +  single_dti', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[1,0].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[1,0].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "# =====================single_dti====================================\n",
    "mdf1 = MixedLM.from_formula('double ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('single_dti ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[2,0].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[2,0].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)      \n",
    "\n",
    "axes[0,0].set(xlabel='Area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa101c-3f36-4896-863d-1ee938baa6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_lst = []\n",
    "attribute = 'area'\n",
    "qq_label = 0\n",
    "\n",
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == '12-005':\n",
    "        X = temp[['amp','single_dtf','single_dti']]\n",
    "    elif subj == 'AllSubjects':\n",
    "        temp = df_AllSub.copy().reset_index(drop=True)\n",
    "        length_2 = len(df_AllSub[df_AllSub.subject != '52-001'])\n",
    "        temp = temp.drop(['freq'], axis=1)\n",
    "        X = temp[['amp','single_dtf','single_dti','subject']]\n",
    "    elif subj == '52-001':\n",
    "        X = temp[['amp','single_dtf']]\n",
    "    else: \n",
    "        X = temp[['amp','single_dtf']]\n",
    "        \n",
    "    if subj == 'AllSubjects':\n",
    "        temp['double'] = (temp['double'])**(1/3)\n",
    "        \n",
    "        md = MixedLM.from_formula('double ~ amp + single_dtf + single_dti', data=temp, \n",
    "                                     groups=temp['subject'])\n",
    "        mdf = md.fit()\n",
    "        print(mdf.summary())\n",
    "        features = temp.drop(['double'], axis=1)\n",
    "        label = temp['double']\n",
    "        print(normal_errors_assumption(mdf, features, label))\n",
    "        \n",
    "        plt.figure()\n",
    "        re = calculate_residuals(mdf, features, label)\n",
    "        sm.qqplot(mdf.resid,line='r',ax = axes_qq[0, qq_label])\n",
    "        X = temp[['amp' , 'single_dtf' , 'single_dti']]\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)] for i in range(len(X.columns))])\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('amp ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'amp', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                             mdf.params['amp'], mdf.pvalues['amp']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('single_dtf ~ amp +  single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dtf', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dtf'], mdf.pvalues['single_dtf']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('single_dti ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dti', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dti'], mdf.pvalues['single_dti']]))\n",
    "\n",
    "    else: \n",
    "        y = (temp.double)**(1/3)\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X2)\n",
    "        est2 = est.fit()\n",
    "        print(subj)\n",
    "        print(est2.summary())\n",
    "        print(normal_errors_assumption(est2, X2, y, p_value_thresh=0.001))\n",
    "        plt.figure()\n",
    "        sm.qqplot(calculate_residuals(est2, X2, y)['Residuals'],line='q',ax = axes_qq[0, qq_label])\n",
    "        print('\\nvariance inflation factor: ')\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)] for i in range(len(X.columns))])\n",
    "        X['double'] = (temp.double)**(1/3)\n",
    "        pcorr = X.pcorr()['double']\n",
    "        for name in pcorr.index[:-1]:\n",
    "            summary_lst.append(np.array([attribute, subj, name, pcorr[name], est2.params[name], est2.pvalues[name]]))\n",
    "            \n",
    "    qq_label += 1\n",
    "\n",
    "summary[attribute] = summary_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d49df3-6e72-4cfc-b962-5c74fc9fb9d3",
   "metadata": {},
   "source": [
    "### major_axis_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f73eae-ba33-4bfc-9bd1-838f48c7f836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_AllSub = pd.DataFrame()\n",
    "\n",
    "condition_list = [0]  \n",
    "label_list = ['SpatialSummation','MultiElectrode']\n",
    "label_list = ['MultiElectrode']\n",
    "for condition in condition_list:\n",
    "    for label in range(1):\n",
    "        data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "        data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "        lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "        lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        double = []\n",
    "        single_dtf = []\n",
    "        single_dti = []\n",
    "        lst_subject = []\n",
    "        \n",
    "        distance = []\n",
    "        amp = []\n",
    "        freq = []\n",
    "        electrode = []\n",
    "        across = []\n",
    "        along = []\n",
    "        for i in range(len(lst)):\n",
    "            electrode1 = lst.electrode1[i]\n",
    "            electrode2 = lst.electrode2[i]\n",
    "            temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            close_electrode = too_close(temp1.subject[0], delta_y=100, delta_rot=5)\n",
    "            close_electrode = []\n",
    "            \n",
    "            if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "                if electrode1 not in close_electrode and electrode2 not in close_electrode:\n",
    "                    \n",
    "                    count = 0\n",
    "                    for j in range(len(double_temp)):\n",
    "                        count += sum(double_temp['major_axis_length'][j])\n",
    "                    double.append(count/len(double_temp))\n",
    "                    single_dtf.append((temp1.distance_to_fovea[0] + temp2.distance_to_fovea[0])/2)\n",
    "                    single_dti.append((temp1.distance_to_implant[0] + temp2.distance_to_implant[0])/2)\n",
    "                    lst_subject.append(temp1.subject[0])\n",
    "\n",
    "                    subject = shapes.subject_params[temp1.subject[0]]\n",
    "                    implant,model = shapes.model_from_params(subject)\n",
    "\n",
    "                    arr = dist_across_along([electrode1], [electrode2], implant, model,strategy='radial')\n",
    "                    across.append(arr[0,1])\n",
    "                    along.append(arr[0,2])\n",
    "                    \n",
    "                    e1_x = implant[electrode1].x\n",
    "                    e1_y = implant[electrode1].y\n",
    "                    e2_x = implant[electrode2].x\n",
    "                    e2_y = implant[electrode2].y\n",
    "\n",
    "                    distance.append(math.sqrt((e1_x - e2_x)**2 + (e1_y - e2_y)**2))\n",
    "                    \n",
    "\n",
    "                    amp.append(lst.amp1[i])\n",
    "                    freq.append(lst.freq[i])\n",
    "\n",
    "        df_investigate = pd.DataFrame({\n",
    "                                       'double':double, \n",
    "                                       'freq':freq,\n",
    "                                       'amp':amp,\n",
    "                                       'single_dtf':single_dtf,\n",
    "                                       'single_dti':single_dti,\n",
    "            'distance':distance,\n",
    "                                        'across':across,\n",
    "                                        'along':along,\n",
    "                                       'subject':lst_subject\n",
    "                                      })\n",
    "        \n",
    "        df_AllSub = df_investigate.copy()\n",
    "        \n",
    "\n",
    "        temp = df_investigate[(df_investigate.amp == 2) & (df_investigate.freq == 20) & \n",
    "                              (df_investigate.single_dti == 0) & \n",
    "                              (df_investigate.single_dtf > 2950) & (df_investigate.single_dtf < 3450)]\n",
    "        temp = temp.groupby(['amp','freq','subject']).mean().reset_index()\n",
    "        df = pd.DataFrame({})\n",
    "        for subj in temp.subject:\n",
    "            df_investigate_temp = df_investigate[df_investigate.subject == subj]\n",
    "            df_investigate_temp['double'] = df_investigate_temp['double'] / temp[temp.subject == subj].iloc[0]['double']\n",
    "            filename = subj + label_list[label]\n",
    "            df_investigate_temp.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')\n",
    "            df = pd.concat([df, df_investigate_temp])\n",
    "        df_investigate = df.copy()\n",
    "        filename = label_list[label]\n",
    "        df_investigate.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b6e74-1086-4ab7-9370-1ed775c63a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 2.5\n",
    "\n",
    "removed_indices = []\n",
    "total_len = 0\n",
    "copy = df_investigate.copy()\n",
    "df_AllSub = df_investigate.copy()\n",
    "df_s = pd.DataFrame({})\n",
    "for subj in ['12-005','51-009','52-001','All']:\n",
    "    if subj != 'All': df_t = copy[copy.subject == subj].reset_index(drop=True)\n",
    "    else: df_t = copy.copy()\n",
    "    \n",
    "    if subj != '12-005' and subj != 'All': total_len += len(df_t)\n",
    "    \n",
    "    df_t['amp'] = (df_t['amp'] - df_t['amp'].mean()) / df_t['amp'].std()\n",
    "    df_t['single_dti'] = (df_t['single_dti'] - df_t['single_dti'].mean()) / df_t['single_dti'].std()\n",
    "    df_t['single_dtf'] = (df_t['single_dtf'] - df_t['single_dtf'].mean()) / df_t['single_dtf'].std()\n",
    "    \n",
    "    if subj != 'All': \n",
    "        before_filtering = set(df_t.index)\n",
    "        df_t = df_t.fillna(0)\n",
    "        df_t = df_t[(abs(df_t.amp) <threshold) & \n",
    "                    (abs(df_t.single_dti) < threshold) & (abs(df_t.single_dtf) < threshold)]\n",
    "\n",
    "        removed_indices.extend([x + total_len for x in list(before_filtering - set(df_t.index))])\n",
    "        df_s = pd.concat([df_s, df_t])\n",
    "        df_s = df_s.fillna(0)\n",
    "    else: df_AllSub = df_t.copy()\n",
    "        \n",
    "df_investigate = df_s.copy().reset_index(drop=True)\n",
    "df_AllSub = df_AllSub.reset_index(drop=True).drop(removed_indices).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e02f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 2.5\n",
    "# df_AllSub = df_AllSub[(df_AllSub.amp <threshold) & (df_AllSub.across < threshold) \n",
    "#                       & (df_AllSub.along < threshold)].reset_index(drop=True)\n",
    "# df_investigate = df_investigate[(df_investigate.amp <threshold) \n",
    "#                                 & (df_investigate.single_dtf < threshold) \n",
    "#                                 & (df_investigate.across < threshold) \n",
    "#                                 & (df_investigate.along < threshold)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b98efd-f436-4ede-a97c-1b3e21553198",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # fig, axs= plt.subplots(ncols=3, figsize=(21, 7))\n",
    "# column_lst = ['amp','single_dti', 'single_dtf','across', 'along']\n",
    "# name_lst = ['Amplitude','Electrode-Retina Distance', 'Electrode-Fovea Distance','Between-Axon Distance','Along-Axon Distance']\n",
    "# for dv in range(5):\n",
    "#     reg = LinearRegression().fit(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]], df_AllSub[['double']])\n",
    "#     y_predicted = reg.predict(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     y = df_AllSub[['double']]-y_predicted\n",
    "\n",
    "#     reg = LinearRegression().fit(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]], df_AllSub[column_lst[dv]])\n",
    "#     y_predicted = reg.predict(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     x = df_AllSub[column_lst[dv]]-y_predicted\n",
    "#     df_AllSub['x'] = x\n",
    "#     df_AllSub['y'] = y\n",
    "#     subject = ['12-005','51-009','52-001']\n",
    "#     marker_lst = ['o','s','^']\n",
    "#     color_lst = ['#1E88E5', '#FFC107','#004D40']\n",
    "#     for i in range(len(subject)):\n",
    "#         temp = df_AllSub[df_AllSub.subject == subject[i]]\n",
    "#         axs[2, dv].plot(temp['x'],temp['y'],marker_lst[i], color=color_lst[i],alpha=0.6,markersize=13)\n",
    "# #     axs[2, dv].legend(subject, loc='upper right',prop={'size': 20})\n",
    "#     reg = LinearRegression().fit(np.array(x).reshape(-1,1),np.array(y).reshape(-1,1))\n",
    "#     y_pred = reg.predict(np.array(x).reshape(-1,1))\n",
    "#     axs[2, dv].plot(x, y_pred,'-', color=\"black\",linewidth=2)\n",
    "# #     axs[dv].set(xlabel = name_lst[dv], ylabel = 'Major Axis Length',ylim=(-0.7,0.8),xlim=(-2,3.4))\n",
    "# #     axs[dv].set(xlabel = name_lst[dv],ylim=(-0.75,0.8),xlim=(-2,3.5))\n",
    "#     axs[2, dv].set(ylim=(-0.75,0.9),xlim=(-2,3.5))\n",
    "#     axs[2, 0].set(ylabel = 'Major Axis Length')\n",
    "#     axs[2, dv].tick_params(axis='both',  labelsize=18)\n",
    "    \n",
    "# #     axs[2, dv].get_xaxis().set_visible(False)\n",
    "# #     if dv>0:\n",
    "# #         axs[2, dv].get_yaxis().set_visible(False)\n",
    "        \n",
    "#     axs[2, dv].yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    \n",
    "#     for item in ([axs[2, dv].xaxis.label, axs[2, dv].yaxis.label]):\n",
    "#         item.set_fontsize(30)\n",
    "# # fig.savefig('/home/yuchen/paper/12b. Double-Electrode Major Axis Length.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd65758",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = ['12-005','51-009','52-001']\n",
    "marker_lst = ['o','s','^']\n",
    "color_lst = ['#1E88E5', '#FFC107','#004D40']\n",
    "\n",
    "temp = df_AllSub.copy().reset_index(drop=True)\n",
    "temp = temp.drop(['freq'], axis=1)\n",
    "temp['double'] = (temp['double'])**(1/2)\n",
    "# ====================amp=====================================\n",
    "mdf1 = MixedLM.from_formula('double ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('amp ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[0,2].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[0,2].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "# ======================single_dtf==================================\n",
    "mdf1 = MixedLM.from_formula('double ~ amp + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('single_dtf ~ amp +  single_dti', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[1,2].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[1,2].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "# =====================single_dti====================================\n",
    "mdf1 = MixedLM.from_formula('double ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('single_dti ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[2,2].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[2,2].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)      \n",
    "\n",
    "axes[0,2].set(ylabel='Major Axis Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2051b-f8a3-40bf-8e36-f1808fe2a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_lst = []\n",
    "attribute = 'major'\n",
    "qq_label = 0\n",
    "\n",
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == '12-005':\n",
    "        X = temp[['amp','single_dtf','single_dti']]\n",
    "    elif subj == 'AllSubjects':\n",
    "        temp = df_AllSub.copy()\n",
    "        length_2 = len(df_AllSub[df_AllSub.subject != '52-001'])\n",
    "#         temp = temp.drop([length_2+22], axis=0)\n",
    "        temp = temp.drop(['freq'], axis=1)\n",
    "        X = temp[['amp','single_dtf','single_dti','subject']]\n",
    "    elif subj == '52-001':\n",
    "#         temp = temp.drop([22], axis=0)\n",
    "        X = temp[['amp','single_dtf']]\n",
    "    else: \n",
    "        X = temp[['amp','single_dtf']]\n",
    "        \n",
    "    if subj == 'AllSubjects':\n",
    "        temp['double'] = (temp['double'])**(1/2)\n",
    "        md = MixedLM.from_formula('double ~ amp + single_dtf + single_dti', data=temp, \n",
    "                                     groups=temp['subject'])\n",
    "        mdf = md.fit()\n",
    "        print(mdf.summary())\n",
    "        features = temp.drop(['double'], axis=1)\n",
    "        label = temp['double']\n",
    "        print(normal_errors_assumption(mdf, features, label))\n",
    "        features = features.drop(['subject'], axis=1)\n",
    "        \n",
    "        plt.figure()\n",
    "        re = calculate_residuals(mdf, features, label)\n",
    "#         sm.qqplot(calculate_residuals(mdf, features, label)['Residuals'],line='q')\n",
    "        sm.qqplot(mdf.resid,line='q',ax = axes_qq[2, qq_label])\n",
    "        X = temp[['amp' , 'single_dtf' , 'single_dti']]\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)] for i in range(len(X.columns))])\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('amp ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'amp1', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                             mdf.params['amp'], mdf.pvalues['amp']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('single_dtf ~ amp +  single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dtf', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dtf'], mdf.pvalues['single_dtf']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('single_dti ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dti', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dti'], mdf.pvalues['single_dti']]))\n",
    "    else: \n",
    "        y = (temp.double)**(1/2)\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X2)\n",
    "        est2 = est.fit()\n",
    "        print(subj)\n",
    "        print(est2.summary())\n",
    "        print(normal_errors_assumption(est2, X2, y, p_value_thresh=0.001))\n",
    "        print('\\nvariance inflation factor: ')\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)]\n",
    "                              for i in range(len(X.columns))])\n",
    "        plt.figure()\n",
    "        re = calculate_residuals(est2, X2, y)\n",
    "        sm.qqplot(calculate_residuals(est2, X2, y)['Residuals'],line='q',ax = axes_qq[2, qq_label])\n",
    "        X['double'] = (temp.double)**(1/2)\n",
    "        pcorr = X.pcorr()['double']\n",
    "        for name in pcorr.index[:-1]:\n",
    "            summary_lst.append(np.array([attribute, subj, name, pcorr[name], est2.params[name], est2.pvalues[name]]))\n",
    "    qq_label += 1\n",
    "\n",
    "summary[attribute] = summary_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9921106-a819-4eab-968e-f4b729a6d78a",
   "metadata": {},
   "source": [
    "### minor_axis_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03594567-f961-46c5-b6b2-10549ea502de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_AllSub = pd.DataFrame()\n",
    "\n",
    "condition_list = [0]  \n",
    "label_list = ['MultiElectrode']\n",
    "for condition in condition_list:\n",
    "    for label in range(1):\n",
    "        data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "        data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "        lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "        lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        double = []\n",
    "        single_dtf = []\n",
    "        single_dti = []\n",
    "        lst_subject = []\n",
    "        \n",
    "        distance = []\n",
    "        amp = []\n",
    "        freq = []\n",
    "        electrode = []\n",
    "        across = []\n",
    "        along = []\n",
    "        for i in range(len(lst)):\n",
    "            electrode1 = lst.electrode1[i]\n",
    "            electrode2 = lst.electrode2[i]\n",
    "            temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            close_electrode = too_close(temp1.subject[0], delta_y=100, delta_rot=5)\n",
    "            close_electrode = []\n",
    "            \n",
    "            if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "                if electrode1 not in close_electrode and electrode2 not in close_electrode:\n",
    "                    \n",
    "                    count = 0\n",
    "                    for j in range(len(double_temp)):\n",
    "                        count += sum(double_temp['minor_axis_length'][j])\n",
    "                    double.append(count/len(double_temp))\n",
    "                    single_dtf.append((temp1.distance_to_fovea[0] + temp2.distance_to_fovea[0])/2)\n",
    "                    single_dti.append((temp1.distance_to_implant[0] + temp2.distance_to_implant[0])/2)\n",
    "                    lst_subject.append(temp1.subject[0])\n",
    "\n",
    "                    subject = shapes.subject_params[temp1.subject[0]]\n",
    "                    implant,model = shapes.model_from_params(subject)\n",
    "\n",
    "                    arr = dist_across_along([electrode1], [electrode2], implant, model,strategy='radial')\n",
    "                    across.append(arr[0,1])\n",
    "                    along.append(arr[0,2])\n",
    "\n",
    "                    e1_x = implant[electrode1].x\n",
    "                    e1_y = implant[electrode1].y\n",
    "                    e2_x = implant[electrode2].x\n",
    "                    e2_y = implant[electrode2].y\n",
    "\n",
    "                    distance.append(math.sqrt((e1_x - e2_x)**2 + (e1_y - e2_y)**2))\n",
    "\n",
    "                    amp.append(lst.amp1[i])\n",
    "                    freq.append(lst.freq[i])\n",
    "\n",
    "        df_investigate = pd.DataFrame({\n",
    "                                       'double':double, \n",
    "                                       'freq':freq,\n",
    "                                       'amp':amp,\n",
    "                                       'single_dtf':single_dtf,\n",
    "                                       'single_dti':single_dti,\n",
    "                                        'across':across,\n",
    "                                        'along':along,\n",
    "            'distance':distance,\n",
    "                                       'subject':lst_subject\n",
    "                                      })\n",
    "\n",
    "        temp = df_investigate[(df_investigate.amp == 2) & (df_investigate.freq == 20) & \n",
    "                              (df_investigate.single_dti == 0) & \n",
    "                              (df_investigate.single_dtf > 2950) & (df_investigate.single_dtf < 3450)]\n",
    "        temp = temp.groupby(['amp','freq','subject']).mean().reset_index()\n",
    "        df = pd.DataFrame({})\n",
    "        for subj in temp.subject:\n",
    "            df_investigate_temp = df_investigate[df_investigate.subject == subj]\n",
    "            df_investigate_temp['double'] = df_investigate_temp['double'] / temp[temp.subject == subj].iloc[0]['double']\n",
    "            filename = subj + label_list[label]\n",
    "            df_investigate_temp.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')\n",
    "            df = pd.concat([df, df_investigate_temp])\n",
    "        df_investigate = df.copy()\n",
    "        filename = label_list[label]\n",
    "        df_investigate.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a2cca3-c3dd-453d-a80f-0cf6d7f56c13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 2.5\n",
    "\n",
    "removed_indices = []\n",
    "total_len = 0\n",
    "copy = df_investigate.copy()\n",
    "df_AllSub = df_investigate.copy()\n",
    "df_s = pd.DataFrame({})\n",
    "for subj in ['12-005','51-009','52-001','All']:\n",
    "    if subj != 'All': df_t = copy[copy.subject == subj].reset_index(drop=True)\n",
    "    else: df_t = copy.copy()\n",
    "    \n",
    "    if subj != '12-005' and subj != 'All': total_len += len(df_t)\n",
    "    \n",
    "    df_t['amp'] = (df_t['amp'] - df_t['amp'].mean()) / df_t['amp'].std()\n",
    "    df_t['single_dti'] = (df_t['single_dti'] - df_t['single_dti'].mean()) / df_t['single_dti'].std()\n",
    "    df_t['single_dtf'] = (df_t['single_dtf'] - df_t['single_dtf'].mean()) / df_t['single_dtf'].std()\n",
    "    \n",
    "    if subj != 'All': \n",
    "        before_filtering = set(df_t.index)\n",
    "        df_t = df_t.fillna(0)\n",
    "        df_t = df_t[(abs(df_t.amp) <threshold) & \n",
    "                    (abs(df_t.single_dti) < threshold) & (abs(df_t.single_dtf) < threshold)]\n",
    "\n",
    "        removed_indices.extend([x + total_len for x in list(before_filtering - set(df_t.index))])\n",
    "        df_s = pd.concat([df_s, df_t])\n",
    "        df_s = df_s.fillna(0)\n",
    "    else: df_AllSub = df_t.copy()\n",
    "        \n",
    "df_investigate = df_s.copy().reset_index(drop=True)\n",
    "df_AllSub = df_AllSub.reset_index(drop=True).drop(removed_indices).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e5811b-b34f-4065-a154-6cb7880e8e99",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # fig, axs= plt.subplots(ncols=3, figsize=(21, 7))\n",
    "# column_lst = ['amp','single_dti', 'single_dtf','across', 'along']\n",
    "# name_lst = ['Amplitude','Electrode-Retina Distance', 'Electrode-Fovea Distance','Between-Axon Distance','Along-Axon Distance']\n",
    "# for dv in range(5):\n",
    "#     reg = LinearRegression().fit(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]], df_AllSub[['double']])\n",
    "#     y_predicted = reg.predict(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     y = df_AllSub[['double']]-y_predicted\n",
    "\n",
    "#     reg = LinearRegression().fit(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]], df_AllSub[column_lst[dv]])\n",
    "#     y_predicted = reg.predict(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     x = df_AllSub[column_lst[dv]]-y_predicted\n",
    "#     df_AllSub['x'] = x\n",
    "#     df_AllSub['y'] = y\n",
    "#     subject = ['12-005','51-009','52-001']\n",
    "#     marker_lst = ['o','s','^']\n",
    "#     color_lst = ['#1E88E5', '#FFC107','#004D40']\n",
    "#     for i in range(len(subject)):\n",
    "#         temp = df_AllSub[df_AllSub.subject == subject[i]]\n",
    "#         axs[3, dv].plot(temp['x'],temp['y'],marker_lst[i], color=color_lst[i],alpha=0.6,markersize=13)\n",
    "# #     axs[3, dv].legend(subject, loc='upper right',prop={'size': 20})\n",
    "#     reg = LinearRegression().fit(np.array(x).reshape(-1,1),np.array(y).reshape(-1,1))\n",
    "#     y_pred = reg.predict(np.array(x).reshape(-1,1))\n",
    "#     axs[3, dv].plot(x, y_pred,'-', color=\"black\",linewidth=2)\n",
    "#     axs[3, dv].set(xlabel = name_lst[dv],ylim=(-1.5,2.3),xlim=(-2,3.5))\n",
    "#     axs[3, 0].set(ylabel = 'Minor Axis Length')\n",
    "#     axs[3, dv].tick_params(axis='both',  labelsize=18)\n",
    "\n",
    "# #     if dv>0:\n",
    "# #         axs[3, dv].get_yaxis().set_visible(False)\n",
    "#     axs[3, dv].yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "        \n",
    "#     for item in ([axs[3, dv].xaxis.label, axs[3, dv].yaxis.label]):\n",
    "#         item.set_fontsize(30)\n",
    "# # fig.savefig('/home/yuchen/paper/12c. Double-Electrode Minor Axis Length.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a473263",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = ['12-005','51-009','52-001']\n",
    "marker_lst = ['o','s','^']\n",
    "color_lst = ['#1E88E5', '#FFC107','#004D40']\n",
    "\n",
    "temp = df_AllSub.copy().reset_index(drop=True)\n",
    "temp = temp.drop(['freq'], axis=1)\n",
    "temp['double'] = (temp['double'])**(1/2)\n",
    "# ====================amp=====================================\n",
    "mdf1 = MixedLM.from_formula('double ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('amp ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[0,3].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[0,3].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "# ======================single_dtf==================================\n",
    "mdf1 = MixedLM.from_formula('double ~ amp + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('single_dtf ~ amp +  single_dti', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[1,3].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[1,3].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "# =====================single_dti====================================\n",
    "mdf1 = MixedLM.from_formula('double ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('single_dti ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[2,3].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[2,3].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)      \n",
    "\n",
    "axes[0,3].set(ylabel='Minor Axis Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1b0b8-2f95-4aef-b6b1-a26294ffab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_lst = []\n",
    "attribute = 'minor'\n",
    "qq_label = 0\n",
    "\n",
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == '12-005':\n",
    "        X = temp[['amp','single_dtf','single_dti']]\n",
    "    elif subj == 'AllSubjects':\n",
    "        temp = df_AllSub.copy()\n",
    "        length_2 = len(df_AllSub[df_AllSub.subject != '52-001'])\n",
    "#         temp = temp.drop([length_2+22], axis=0)\n",
    "        temp = temp.drop(['freq'], axis=1)\n",
    "        X = temp[['amp','single_dtf','single_dti','subject']]\n",
    "    elif subj == '52-001':\n",
    "#         temp = temp.drop([22], axis=0)\n",
    "        X = temp[['amp','single_dtf']]\n",
    "    else: \n",
    "        X = temp[['amp','single_dtf']]\n",
    "        \n",
    "    if subj == 'AllSubjects':\n",
    "#         temp['double'] = (temp['double'])**(1/2)\n",
    "        md = MixedLM.from_formula('double ~ amp + single_dtf + single_dti', data=temp, \n",
    "                                     groups=temp['subject'])\n",
    "        mdf = md.fit()\n",
    "        print(mdf.summary())\n",
    "        features = temp.drop(['double'], axis=1)\n",
    "        label = temp['double']\n",
    "        print(normal_errors_assumption(mdf, features, label))\n",
    "        features = features.drop(['subject'], axis=1)\n",
    "        \n",
    "        plt.figure()\n",
    "        re = calculate_residuals(mdf, features, label)\n",
    "#         plt.scatter(re['Predicted'], re['Residuals'])\n",
    "#         sm.qqplot(calculate_residuals(mdf, features, label)['Residuals'],line='q')\n",
    "        sm.qqplot(mdf.resid,line='q',ax = axes_qq[3, qq_label])\n",
    "        X = temp[['amp' , 'single_dtf' , 'single_dti']]\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)] for i in range(len(X.columns))])\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('amp ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'amp1', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                             mdf.params['amp'], mdf.pvalues['amp']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('single_dtf ~ amp +  single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dtf', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dtf'], mdf.pvalues['single_dtf']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('single_dti ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dti', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dti'], mdf.pvalues['single_dti']]))\n",
    "\n",
    "    else: \n",
    "        y = (temp.double)**(1/2)\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X2)\n",
    "        est2 = est.fit()\n",
    "        print(subj)\n",
    "        print(est2.summary())\n",
    "        print(normal_errors_assumption(est2, X2, y, p_value_thresh=0.001))\n",
    "        print('\\nvariance inflation factor: ')\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)]\n",
    "                              for i in range(len(X.columns))])\n",
    "        \n",
    "        plt.figure()\n",
    "        re = calculate_residuals(est2, X2, y)\n",
    "        sm.qqplot(calculate_residuals(est2, X2, y)['Residuals'],line='q',ax = axes_qq[3, qq_label])\n",
    "        X['double'] = (temp.double)**(1/2)\n",
    "        pcorr = X.pcorr()['double']\n",
    "        for name in pcorr.index[:-1]:\n",
    "            summary_lst.append(np.array([attribute, subj, name, pcorr[name], est2.params[name], est2.pvalues[name]]))\n",
    "            \n",
    "    qq_label += 1\n",
    "\n",
    "summary[attribute] = summary_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a729b6f-4caa-4f5d-8476-d1d60e6f3e76",
   "metadata": {},
   "source": [
    "### perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be0f611-d5d2-4c7f-9f10-0cede22a4601",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AllSub = pd.DataFrame()\n",
    "\n",
    "condition_list = [0]  \n",
    "label_list = ['MultiElectrode']\n",
    "for condition in condition_list:\n",
    "    for label in range(1):\n",
    "        data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "        data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "        lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "        lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        double = []\n",
    "        single_dtf = []\n",
    "        single_dti = []\n",
    "        lst_subject = []\n",
    "        \n",
    "        distance = []\n",
    "        amp = []\n",
    "        freq = []\n",
    "        electrode = []\n",
    "        across = []\n",
    "        along = []\n",
    "        for i in range(len(lst)):\n",
    "            electrode1 = lst.electrode1[i]\n",
    "            electrode2 = lst.electrode2[i]\n",
    "            temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            close_electrode = too_close(temp1.subject[0], delta_y=100, delta_rot=5)\n",
    "            close_electrode = []\n",
    "            \n",
    "            if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "                if electrode1 not in close_electrode and electrode2 not in close_electrode:\n",
    "                    \n",
    "                    count = 0\n",
    "                    for j in range(len(double_temp)):\n",
    "                        count += sum(double_temp['perimeter'][j])\n",
    "                    double.append(count/len(double_temp))\n",
    "                    single_dtf.append((temp1.distance_to_fovea[0] + temp2.distance_to_fovea[0])/2)\n",
    "                    single_dti.append((temp1.distance_to_implant[0] + temp2.distance_to_implant[0])/2)\n",
    "                    lst_subject.append(temp1.subject[0])\n",
    "\n",
    "                    subject = shapes.subject_params[temp1.subject[0]]\n",
    "                    implant,model = shapes.model_from_params(subject)\n",
    "                    \n",
    "                    e1_x = implant[electrode1].x\n",
    "                    e1_y = implant[electrode1].y\n",
    "                    e2_x = implant[electrode2].x\n",
    "                    e2_y = implant[electrode2].y\n",
    "\n",
    "                    distance.append(math.sqrt((e1_x - e2_x)**2 + (e1_y - e2_y)**2))\n",
    "\n",
    "                    arr = dist_across_along([electrode1], [electrode2], implant, model,strategy='radial')\n",
    "                    across.append(arr[0,1])\n",
    "                    along.append(arr[0,2])\n",
    "\n",
    "                    amp.append(lst.amp1[i])\n",
    "                    freq.append(lst.freq[i])\n",
    "\n",
    "        df_investigate = pd.DataFrame({\n",
    "                                       'double':double, \n",
    "                                       'freq':freq,\n",
    "                                       'amp':amp,\n",
    "                                       'single_dtf':single_dtf,\n",
    "                                       'single_dti':single_dti,\n",
    "                                        'across':across,\n",
    "                                        'along':along,\n",
    "            'distance':distance,\n",
    "                                       'subject':lst_subject\n",
    "                                      })\n",
    "        \n",
    "        temp = df_investigate[(df_investigate.amp == 2) & (df_investigate.freq == 20) & \n",
    "                              (df_investigate.single_dti == 0) & \n",
    "                              (df_investigate.single_dtf > 2950) & (df_investigate.single_dtf < 3450)]\n",
    "        temp = temp.groupby(['amp','freq','subject']).mean().reset_index()\n",
    "        df = pd.DataFrame({})\n",
    "        for subj in temp.subject:\n",
    "            df_investigate_temp = df_investigate[df_investigate.subject == subj]\n",
    "            df_investigate_temp['double'] = df_investigate_temp['double'] / temp[temp.subject == subj].iloc[0]['double']\n",
    "            filename = subj + label_list[label]\n",
    "            df_investigate_temp.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')\n",
    "            df = pd.concat([df, df_investigate_temp])\n",
    "        df_investigate = df.copy()\n",
    "        filename = label_list[label]\n",
    "        df_investigate.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e96d7-bef7-4cce-9ddc-45962d8ed890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 2.5\n",
    "\n",
    "removed_indices = []\n",
    "total_len = 0\n",
    "copy = df_investigate.copy()\n",
    "df_AllSub = df_investigate.copy()\n",
    "df_s = pd.DataFrame({})\n",
    "for subj in ['12-005','51-009','52-001','All']:\n",
    "    if subj != 'All': df_t = copy[copy.subject == subj].reset_index(drop=True)\n",
    "    else: df_t = copy.copy()\n",
    "    \n",
    "    if subj != '12-005' and subj != 'All': total_len += len(df_t)\n",
    "    \n",
    "    df_t['amp'] = (df_t['amp'] - df_t['amp'].mean()) / df_t['amp'].std()\n",
    "    df_t['single_dti'] = (df_t['single_dti'] - df_t['single_dti'].mean()) / df_t['single_dti'].std()\n",
    "    df_t['single_dtf'] = (df_t['single_dtf'] - df_t['single_dtf'].mean()) / df_t['single_dtf'].std()\n",
    "    \n",
    "    if subj != 'All': \n",
    "        before_filtering = set(df_t.index)\n",
    "        df_t = df_t.fillna(0)\n",
    "        df_t = df_t[(abs(df_t.amp) <threshold) & \n",
    "                    (abs(df_t.single_dti) < threshold) & (abs(df_t.single_dtf) < threshold)]\n",
    "\n",
    "        removed_indices.extend([x + total_len for x in list(before_filtering - set(df_t.index))])\n",
    "        df_s = pd.concat([df_s, df_t])\n",
    "        df_s = df_s.fillna(0)\n",
    "    else: df_AllSub = df_t.copy()\n",
    "        \n",
    "df_investigate = df_s.copy().reset_index(drop=True)\n",
    "df_AllSub = df_AllSub.reset_index(drop=True).drop(removed_indices).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 2.5\n",
    "# df_AllSub = df_AllSub[(df_AllSub.amp <threshold) & (df_AllSub.across < threshold) \n",
    "#                       & (df_AllSub.along < threshold)].reset_index(drop=True)\n",
    "# df_investigate = df_investigate[(df_investigate.amp <threshold) \n",
    "#                                 & (df_investigate.single_dtf < threshold) \n",
    "#                                 & (df_investigate.across < threshold) \n",
    "#                                 & (df_investigate.along < threshold)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb0ed3c-320d-4b3b-afef-c21a6c0e404d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # fig, axs= plt.subplots(ncols=3, figsize=(21, 7))\n",
    "# column_lst = ['amp','single_dti', 'single_dtf','across', 'along']\n",
    "# name_lst = ['Amplitude','Electrode-Retina Distance', 'Electrode-Fovea Distance','Between-Axon Distance','Along-Axon Distance']\n",
    "# for dv in range(5):\n",
    "#     reg = LinearRegression().fit(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]], df_AllSub[['double']])\n",
    "#     y_predicted = reg.predict(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     y = df_AllSub[['double']]-y_predicted\n",
    "\n",
    "#     reg = LinearRegression().fit(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]], df_AllSub[column_lst[dv]])\n",
    "#     y_predicted = reg.predict(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     x = df_AllSub[column_lst[dv]]-y_predicted\n",
    "#     df_AllSub['x'] = x\n",
    "#     df_AllSub['y'] = y\n",
    "#     subject = ['12-005','51-009','52-001']\n",
    "#     marker_lst = ['o','s','^']\n",
    "#     color_lst = ['#1E88E5', '#FFC107','#004D40']\n",
    "#     for i in range(len(subject)):\n",
    "#         temp = df_AllSub[df_AllSub.subject == subject[i]]\n",
    "#         axs[1, dv].plot(temp['x'],temp['y'],marker_lst[i], color=color_lst[i],alpha=0.6,markersize=13)\n",
    "# #     axs[1, dv].legend(subject, loc='upper right',prop={'size': 20})\n",
    "#     reg = LinearRegression().fit(np.array(x).reshape(-1,1),np.array(y).reshape(-1,1))\n",
    "#     y_pred = reg.predict(np.array(x).reshape(-1,1))\n",
    "#     axs[1, dv].plot(x, y_pred,'-', color=\"black\",linewidth=2)\n",
    "#     axs[1, dv].set(ylim=(-0.75,0.7),xlim=(-2,3.5))\n",
    "#     axs[1, 0].set(ylabel = 'Perimeter')\n",
    "#     axs[1, dv].tick_params(axis='both',  labelsize=18)\n",
    "    \n",
    "# #     axs[1, dv].get_xaxis().set_visible(False)\n",
    "# #     if dv>0:\n",
    "# #         axs[1, dv].get_yaxis().set_visible(False)\n",
    "#     axs[1, dv].yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "#     for item in ([axs[1, dv].xaxis.label, axs[1, dv].yaxis.label]):\n",
    "#         item.set_fontsize(30)\n",
    "# # fig.savefig('/home/yuchen/paper/12d. Double-Electrode Perimeter.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c3d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.savefig('/home/yuchen/paper/fig-pcor-double.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = ['12-005','51-009','52-001']\n",
    "marker_lst = ['o','s','^']\n",
    "color_lst = ['#1E88E5', '#FFC107','#004D40']\n",
    "\n",
    "temp = df_AllSub.copy().reset_index(drop=True)\n",
    "temp = temp.drop(['freq'], axis=1)\n",
    "temp['double'] = (temp['double'])**(1/2)\n",
    "# ====================amp=====================================\n",
    "mdf1 = MixedLM.from_formula('double ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('amp ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[0,1].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[0,1].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "# ======================single_dtf==================================\n",
    "mdf1 = MixedLM.from_formula('double ~ amp + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('single_dtf ~ amp +  single_dti', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[1,1].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[1,1].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "# =====================single_dti====================================\n",
    "mdf1 = MixedLM.from_formula('double ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('single_dti ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[2,1].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=65)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[2,1].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)      \n",
    "\n",
    "axes[0,1].set(ylabel='Perimeter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef66200-ef47-453d-9d85-6f8711534f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_lst = []\n",
    "attribute = 'perimeter'\n",
    "qq_label = 0\n",
    "\n",
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == '12-005':\n",
    "        X = temp[['amp','single_dtf','single_dti']]\n",
    "    elif subj == 'AllSubjects':\n",
    "        temp = df_AllSub.copy()\n",
    "        length_2 = len(df_AllSub[df_AllSub.subject != '52-001'])\n",
    "#         temp = temp.drop([length_2+22], axis=0)\n",
    "        temp = temp.drop(['freq'], axis=1)\n",
    "        X = temp[['amp','single_dtf','single_dti','subject']]\n",
    "    elif subj == '52-001':\n",
    "#         temp = temp.drop([22], axis=0)\n",
    "        X = temp[['amp','single_dtf']]\n",
    "    else: \n",
    "        X = temp[['amp','single_dtf']]\n",
    "    \n",
    "    if subj == 'AllSubjects':\n",
    "        temp['double'] = (temp['double'])**(1/2)\n",
    "        md = MixedLM.from_formula('double ~ amp + single_dtf + single_dti', data=temp, \n",
    "                                     groups=temp['subject'])\n",
    "        mdf = md.fit()\n",
    "        print(mdf.summary())\n",
    "        features = temp.drop(['double'], axis=1)\n",
    "        label = temp['double']\n",
    "        print(normal_errors_assumption(mdf, features, label))\n",
    "        features = features.drop(['subject'], axis=1)\n",
    "        plt.figure()\n",
    "        re = calculate_residuals(mdf, features, label)\n",
    "#         plt.scatter(re['Predicted'], re['Residuals'])\n",
    "#         sm.qqplot(calculate_residuals(mdf, features, label)['Residuals'],line='q')\n",
    "        sm.qqplot(mdf.resid,line='q',ax = axes_qq[1, qq_label])\n",
    "        X = temp[['amp' , 'single_dtf' , 'single_dti']]\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)] for i in range(len(X.columns))])\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('amp ~ single_dtf + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'amp1', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                             mdf.params['amp'], mdf.pvalues['amp']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('single_dtf ~ amp +  single_dti', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dtf', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dtf'], mdf.pvalues['single_dtf']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('single_dti ~ amp + single_dtf', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dti', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dti'], mdf.pvalues['single_dti']]))\n",
    "\n",
    "\n",
    "    else: \n",
    "        y = (temp.double)**(1/2)\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X2)\n",
    "        est2 = est.fit()\n",
    "        print(subj)\n",
    "        print(est2.summary())\n",
    "        print(normal_errors_assumption(est2, X2, y, p_value_thresh=0.001))\n",
    "        print('\\nvariance inflation factor: ')\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)]\n",
    "                              for i in range(len(X.columns))])\n",
    "        \n",
    "        plt.figure()\n",
    "        re = calculate_residuals(est2, X2, y)\n",
    "#         plt.scatter(re['Predicted'], re['Residuals'])\n",
    "        sm.qqplot(calculate_residuals(est2, X2, y)['Residuals'],line='q',ax = axes_qq[1, qq_label])\n",
    "        X['double'] = (temp.double)**(1/2)\n",
    "        pcorr = X.pcorr()['double']\n",
    "        for name in pcorr.index[:-1]:\n",
    "            summary_lst.append(np.array([attribute, subj, name, pcorr[name], est2.params[name], est2.pvalues[name]]))\n",
    "    qq_label += 1\n",
    "\n",
    "summary[attribute] = summary_lst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eacfb38-55c1-49ab-92c2-9719a4a751c0",
   "metadata": {},
   "source": [
    "### orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be010c5e-e555-468a-9162-84254f1d4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AllSub = pd.DataFrame()\n",
    "\n",
    "condition_list = [0]  \n",
    "label_list = ['MultiElectrode']\n",
    "for condition in condition_list:\n",
    "    for label in range(1):\n",
    "        data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "        data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "        lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "        lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        double = []\n",
    "        single_dtf = []\n",
    "        single_dti = []\n",
    "        lst_subject = []\n",
    "        between = []\n",
    "        along = []\n",
    "        \n",
    "        distance = []\n",
    "        amp = []\n",
    "        freq = []\n",
    "        tan = []\n",
    "        electrode = []\n",
    "        for i in range(len(lst)):\n",
    "            electrode1 = lst.electrode1[i]\n",
    "            electrode2 = lst.electrode2[i]\n",
    "            temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "            if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "                count = 0\n",
    "                for j in range(len(double_temp)):\n",
    "                    count += mean(double_temp['orientation_new'][j])\n",
    "                double.append(count/len(double_temp))\n",
    "                single_dtf.append((temp1.distance_to_fovea[0] + temp2.distance_to_fovea[0])/2)\n",
    "                single_dti.append((temp1.distance_to_implant[0] + temp2.distance_to_implant[0])/2)\n",
    "                lst_subject.append(temp1.subject[0])\n",
    "                \n",
    "                subject = shapes.subject_params[temp1.subject[0]]\n",
    "                implant,model = shapes.model_from_params(subject)\n",
    "                \n",
    "                e1_x = implant[electrode1].x\n",
    "                e1_y = implant[electrode1].y\n",
    "                e2_x = implant[electrode2].x\n",
    "                e2_y = implant[electrode2].y\n",
    "                \n",
    "                tan.append(mean([model.calc_bundle_tangent(e1_x, e1_y)*-1, model.calc_bundle_tangent(e2_x, e2_y)*-1]))\n",
    "                \n",
    "                distance.append(math.sqrt((e1_x - e2_x)**2 + (e1_y - e2_y)**2))\n",
    "\n",
    "                amp.append(lst.amp1[i])\n",
    "                freq.append(lst.freq[i])\n",
    "\n",
    "        df_investigate = pd.DataFrame({\n",
    "                                       'double':double, \n",
    "                                       'freq':freq,\n",
    "                                       'amp':amp,\n",
    "                                        'distance':distance,\n",
    "            'tan':tan,\n",
    "            \n",
    "                                       'single_dtf':single_dtf,\n",
    "                                       'single_dti':single_dti,\n",
    "                                       'subject':lst_subject\n",
    "                                      })\n",
    "        for subj in ['12-005', '51-009', '52-001']:\n",
    "            df_investigate_temp = df_investigate[df_investigate.subject == subj]\n",
    "            filename = subj + label_list[label]\n",
    "            df_investigate_temp.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')\n",
    "        filename = label_list[label]\n",
    "        df_investigate.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')\n",
    "        \n",
    "df_AllSub = df_investigate.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca191404-93a9-401b-b5dd-8b36427f9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_investigate)):\n",
    "    if df_investigate.tan[i] < 0:\n",
    "        df_investigate.at[i,'tan'] = df_investigate.tan[i]+np.pi\n",
    "    if df_investigate.double[i] < 0:\n",
    "        df_investigate.at[i,'double'] = df_investigate.double[i]+np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e122da",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2.5\n",
    "\n",
    "removed_indices = []\n",
    "total_len = 0\n",
    "copy = df_investigate.copy()\n",
    "df_AllSub = df_investigate.copy()\n",
    "df_s = pd.DataFrame({})\n",
    "for subj in ['12-005','51-009','52-001','All']:\n",
    "    if subj != 'All': df_t = copy[copy.subject == subj].reset_index(drop=True)\n",
    "    else: df_t = copy.copy()\n",
    "    \n",
    "    if subj != '12-005' and subj != 'All': total_len += len(df_t)\n",
    "    \n",
    "    df_t['amp'] = (df_t['amp'] - df_t['amp'].mean()) / df_t['amp'].std()\n",
    "    df_t['single_dti'] = (df_t['single_dti'] - df_t['single_dti'].mean()) / df_t['single_dti'].std()\n",
    "    df_t['single_dtf'] = (df_t['single_dtf'] - df_t['single_dtf'].mean()) / df_t['single_dtf'].std()\n",
    "    df_t['tan'] = (df_t['tan'] - df_t['tan'].mean()) / df_t['tan'].std()\n",
    "    \n",
    "    if subj != 'All': \n",
    "        before_filtering = set(df_t.index)\n",
    "        df_t = df_t.fillna(0)\n",
    "        df_t = df_t[(abs(df_t.amp) <threshold) & \n",
    "                    (abs(df_t.single_dti) < threshold) & (abs(df_t.single_dtf) < threshold) & \n",
    "                    (abs(df_t.tan) < threshold)]\n",
    "\n",
    "        removed_indices.extend([x + total_len for x in list(before_filtering - set(df_t.index))])\n",
    "        df_s = pd.concat([df_s, df_t])\n",
    "        df_s = df_s.fillna(0)\n",
    "    else: df_AllSub = df_t.copy()\n",
    "        \n",
    "df_investigate = df_s.copy().reset_index(drop=True)\n",
    "df_AllSub = df_AllSub.reset_index(drop=True).drop(removed_indices).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_AllSub = df_AllSub[(df_AllSub.amp <3) ].reset_index(drop=True)\n",
    "# df_investigate = df_investigate[(df_investigate.amp <3)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e122965-768d-4c80-b964-7b9fca052bf8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig, axs= plt.subplots(ncols=6, figsize=(42, 7))\n",
    "# column_lst = ['amp','single_dtf', 'single_dti','between','along','tan']\n",
    "# name_lst = ['Amplitude','Foveal Eccentricity', 'Electrode-Implant Distance','Between-Axon Distance','Along-Axon Distance', 'Axonal Tangent Line']\n",
    "# for dv in range(6):\n",
    "#     reg = LinearRegression().fit(df_investigate[column_lst[:dv] + column_lst[dv+1 :]], df_investigate[['double']])\n",
    "#     y_predicted = reg.predict(df_investigate[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     y = df_investigate[['double']]-y_predicted\n",
    "\n",
    "#     reg = LinearRegression().fit(df_investigate[column_lst[:dv] + column_lst[dv+1 :]], df_investigate[column_lst[dv]])\n",
    "#     y_predicted = reg.predict(df_investigate[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     x = df_investigate[column_lst[dv]]-y_predicted\n",
    "#     df_investigate['x'] = x\n",
    "#     df_investigate['y'] = y\n",
    "#     subject = ['12-005','51-009','52-001']\n",
    "#     marker_lst = ['o','s','^']\n",
    "#     color_lst = ['#1E88E5', '#FFC107','#004D40']\n",
    "#     for i in range(len(subject)):\n",
    "#         temp = df_investigate[df_investigate.subject == subject[i]]\n",
    "#         axs[dv].plot(temp['x'],temp['y'],marker_lst[i], color=color_lst[i],alpha=0.6,markersize=13)\n",
    "#     axs[dv].legend(subject, loc='upper right',prop={'size': 15})\n",
    "#     reg = LinearRegression().fit(np.array(x).reshape(-1,1),np.array(y).reshape(-1,1))\n",
    "#     y_pred = reg.predict(np.array(x).reshape(-1,1))\n",
    "#     axs[dv].plot(x, y_pred,'-', color=\"black\",linewidth=2)\n",
    "#     axs[dv].set(xlabel = name_lst[dv],ylim=(-2.6,2.6),xlim=(-2.2,3.5))\n",
    "#     axs[0].set(ylabel = 'Orientation')\n",
    "#     axs[dv].tick_params(axis='both',  labelsize=18)\n",
    "    \n",
    "#     for item in ([axs[dv].xaxis.label, axs[dv].yaxis.label]):\n",
    "#         item.set_fontsize(30)\n",
    "# fig.savefig('/home/yuchen/paper/12e. Double-Electrode Orientation.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23231c18-f48b-4fcc-8666-1da40541a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_lst = []\n",
    "attribute = 'orientation'\n",
    "qq_label = 0\n",
    "\n",
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == '12-005':\n",
    "        X = temp[['amp','single_dtf','single_dti','tan']]\n",
    "    elif subj == 'AllSubjects':\n",
    "#         temp = df_AllSub.copy()\n",
    "        temp = df_investigate.copy()\n",
    "        temp = temp.drop(['freq'], axis=1)\n",
    "        X = temp[['amp','single_dtf','single_dti','subject','tan']]\n",
    "    elif subj == '52-001':\n",
    "        X = temp[['amp','single_dtf','tan']]\n",
    "    else: \n",
    "        X = temp[['amp','single_dtf','tan']]\n",
    "    \n",
    "    if subj == 'AllSubjects':\n",
    "        temp['double'] = (temp['double'])\n",
    "        md = MixedLM.from_formula('double ~ amp + single_dtf + single_dti + tan', data=temp, \n",
    "                                     groups=temp['subject'])\n",
    "        mdf = md.fit(reml=False)\n",
    "        print(mdf.summary())\n",
    "        features = temp.drop(['double'], axis=1)\n",
    "        label = temp['double']\n",
    "        print(normal_errors_assumption(mdf, features, label))\n",
    "        features = features.drop(['subject'], axis=1)\n",
    "        \n",
    "        plt.figure()\n",
    "        re = calculate_residuals(mdf, features, label)\n",
    "#         sm.qqplot(calculate_residuals(mdf, features, label)['Residuals'],line='q')\n",
    "#         sm.qqplot(mdf.resid,line='q',ax = axes_qq[-1, qq_label])\n",
    "        X = temp[['amp' , 'single_dtf' , 'single_dti', 'tan']]\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)] for i in range(len(X.columns))])\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ single_dtf + single_dti + tan', data=temp, groups=temp['subject']).fit(reml=False)\n",
    "        mdf2 = MixedLM.from_formula('amp ~ single_dtf + single_dti + tan', data=temp, groups=temp['subject']).fit(reml=False)\n",
    "        summary_lst.append(np.array([attribute, subj, 'amp1', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                             mdf.params['amp'], mdf.pvalues['amp']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dti + tan', data=temp, groups=temp['subject']).fit(reml=False)\n",
    "        mdf2 = MixedLM.from_formula('single_dtf ~ amp +  single_dti + tan', data=temp, groups=temp['subject']).fit(reml=False)\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dtf', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dtf'], mdf.pvalues['single_dtf']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dtf + tan', data=temp, groups=temp['subject']).fit(reml=False)\n",
    "        mdf2 = MixedLM.from_formula('single_dti ~ amp + single_dtf + tan', data=temp, groups=temp['subject']).fit(reml=False)\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dti', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dti'], mdf.pvalues['single_dti']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dtf + single_dti', data=temp, groups=temp['subject']).fit(reml=False)\n",
    "        mdf2 = MixedLM.from_formula('tan ~ amp + single_dtf + single_dti', data=temp, groups=temp['subject']).fit(reml=False)\n",
    "        summary_lst.append(np.array([attribute, subj, 'tan', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['tan'], mdf.pvalues['tan']]))\n",
    "\n",
    "    else: \n",
    "        y = (temp.double)\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X2)\n",
    "        est2 = est.fit()\n",
    "        print(subj)\n",
    "        print(est2.summary())\n",
    "        print(normal_errors_assumption(est2, X2, y, p_value_thresh=0.001))\n",
    "        print('\\nvariance inflation factor: ')\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)]\n",
    "                              for i in range(len(X.columns))])\n",
    "        \n",
    "        plt.figure()\n",
    "        re = calculate_residuals(est2, X2, y)\n",
    "#         sm.qqplot(calculate_residuals(est2, X2, y)['Residuals'],line='q',ax = axes_qq[-1, qq_label])\n",
    "        X['double'] = (temp.double)\n",
    "        pcorr = X.pcorr()['double']\n",
    "        for name in pcorr.index[:-1]:\n",
    "            summary_lst.append(np.array([attribute, subj, name, pcorr[name], est2.params[name], est2.pvalues[name]]))\n",
    "\n",
    "    qq_label += 1\n",
    "    \n",
    "# summary[attribute] = summary_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40464ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_lst, columns=['attribute', 'subject', 'predictor','ppcor', 'coef','p'])\n",
    "sig = []\n",
    "r = []\n",
    "b = []\n",
    "for i in range(len(df)):\n",
    "    p = float(df['p'][i])\n",
    "    if p < 0.001: sig.append('***')\n",
    "    elif p < 0.01: sig.append('**')\n",
    "    elif p < 0.05: sig.append('*')\n",
    "    else: sig.append('')\n",
    "    r_ = float(df['ppcor'][i])\n",
    "    round_ = 3\n",
    "    if abs(r_)<0.1: round_+=1\n",
    "    if abs(r_)<0.01: round_+=1\n",
    "    if abs(r_)<0.001: round_+=1\n",
    "    if abs(r_)<0.0001: round_=9\n",
    "    temp = str(round(r_, round_)).split(\"0.\")\n",
    "    r.append(temp[0] + '.'+temp[1])\n",
    "    b_ = float(df['coef'][i])\n",
    "    round_ = 3\n",
    "    if abs(b_)<0.1: round_+=1\n",
    "    if abs(b_)<0.01: round_+=1\n",
    "    if abs(b_)<0.001: round_+=1\n",
    "    if abs(b_)<0.0001: round_=9\n",
    "    temp = str(round(b_, round_)).split(\"0.\")\n",
    "    b.append(temp[0] + '.'+temp[1])\n",
    "    \n",
    "df['sig'] = sig\n",
    "df['r'] = r\n",
    "df['b'] = b\n",
    "\n",
    "test = df[['attribute', 'subject', 'predictor', 'b', 'sig', 'r','p']]\n",
    "b_sig = []\n",
    "corr = []\n",
    "for i in range(len(test)):\n",
    "    if test.iloc[i]['sig'] != str():\n",
    "        b_sig.append('\\textbf{' + test.iloc[i]['b'] + '}$' +  test.iloc[i]['sig'])\n",
    "        corr.append('\\textbf{' + test.iloc[i]['r'] + '}$')\n",
    "    else:\n",
    "        b_sig.append('' + test.iloc[i]['b'] + '$')\n",
    "        corr.append('' + test.iloc[i]['r'] + '$')\n",
    "test['b_sig'] = b_sig\n",
    "test['corr'] = corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb4b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "temp = test[(test.subject=='52-001')].reset_index(drop=True)\n",
    "results,p,_,_ = statsmodels.stats.multitest.multipletests(temp['p'].astype('float32'), method='bonferroni')\n",
    "temp['results'] = results\n",
    "temp['p_corrected'] = p\n",
    "sig = []\n",
    "for i in range(len(temp)):\n",
    "    p = float(temp['p_corrected'][i])\n",
    "    if p < 0.001: sig.append('***')\n",
    "    elif p < 0.01: sig.append('**')\n",
    "    elif p < 0.05: sig.append('*')\n",
    "    else: sig.append('')\n",
    "temp['sig_corrected'] = sig\n",
    "temp[['attribute', 'subject', 'predictor','b_sig', 'corr', 'sig_corrected']].sort_values(['predictor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[i, j].get_xaxis().set_visible(True)\n",
    "        axes[i, j].get_yaxis().set_visible(True)\n",
    "        axes[i, 0].set(ylim=(-0.5,0.82))\n",
    "        axes[i, 1].set(ylim=(-0.45,0.3))\n",
    "        axes[i, 2].set(ylim=(-0.55,0.38))\n",
    "        axes[i, 3].set(ylim=(-0.68,0.8))\n",
    "        axes[i, j].yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "        axes[i, j].xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "for axs in axes:\n",
    "    for ax in axs:\n",
    "        ax.tick_params(axis='both', which='major', labelsize=13)    \n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        \n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[i, j].set_xlabel('', fontsize=21)\n",
    "        axes[i, j].set_ylabel('', fontsize=21)\n",
    "    \n",
    "axes[0, 0].set_title('Area', fontsize=21)\n",
    "axes[0, 1].set_title('Perimeter', fontsize=21)\n",
    "axes[0, 2].set_title('Major Axis Length', fontsize=21)\n",
    "axes[0, 3].set_title('Minor Axis Length', fontsize=21)\n",
    "\n",
    "axes[0, 0].set_ylabel('Amplitude', fontsize=21)\n",
    "axes[1, 0].set_ylabel('Electrode-Fovea Distance', fontsize=21)\n",
    "axes[2, 0].set_ylabel('Electrode-Retina Distance', fontsize=21)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8766ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('/home/yuchen/shapes/figures/double_ppcor.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc044f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61932feb-b38d-436b-bd5f-0848c475f6a0",
   "metadata": {},
   "source": [
    "### number of phosphene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189089a2-f6c1-412d-b322-6bff8dcf7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_copy.copy()\n",
    "\n",
    "# data_double = data[(data['electrode2'] != str())].reset_index(drop=True)\n",
    "data_double = double_recreated.copy()\n",
    "data_single = data[(data['electrode2'] == str())].reset_index(drop=True)\n",
    "data_single['stim_class'] ='SingleElectrode'\n",
    "df = data_single[['subject', 'electrode1', 'freq', 'amp1']].drop_duplicates().reset_index(drop=True)\n",
    "lst = []\n",
    "lst_phosphene = []\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df_temp = data_single[(data_single['subject'] == df.subject[i]) & (data_single['electrode1'] == df.electrode1[i]) & (data_single['freq'] == df.freq[i]) & (data_single['amp1'] == df.amp1[i])].reset_index(drop=True)\n",
    "    ratio = len(df_temp[df_temp['num_regions']>1]) /len(df_temp)\n",
    "    lst.append(ratio)\n",
    "    lst_phosphene.append(mean(df_temp['num_regions']))\n",
    "    \n",
    "\n",
    "df['phosphene'] = lst_phosphene\n",
    "data_single = df\n",
    "\n",
    "subject = ['12-005', '51-009', '52-001']\n",
    "df = pd.DataFrame({})\n",
    "\n",
    "for subj in subject:\n",
    "    lst_e = []\n",
    "    lst_dtf = []\n",
    "    \n",
    "    s2 = shapes.subject_params[subj]\n",
    "    implant,model = shapes.model_from_params(s2)\n",
    "    for i in string.ascii_uppercase[0:6]: \n",
    "        for j in range(1,11):\n",
    "            electrode = i + str(j)\n",
    "            lst_e.append(electrode)\n",
    "            lst_dtf.append(math.sqrt(implant[electrode].x**2 +implant[electrode].y**2 ))\n",
    "    df_o = pd.DataFrame(lst_e, columns=['electrode1'])\n",
    "    df_o['distance_to_fovea'] = lst_dtf\n",
    "    \n",
    "    if subj == '12-005':\n",
    "        lst_d = [0,0,0,2,7,7,0,0,5,0,\n",
    "                0,0,4,11,13,15,15,3,7,4,\n",
    "                0,0,15,16,17,17,19,16,9,4,\n",
    "                0,0,16,19,15,17,22,25,13,10,\n",
    "                0,0,8,15,14,13,17,23,14,2,\n",
    "                0,0,10,15,13,12,9,11,5]\n",
    "        lst_e = lst_e[:-1]\n",
    "    elif subj == '51-009':\n",
    "        lst_e = ['F1','F2','F3','F4','F5','F6',\n",
    "               'E1','E2','E3','E4','E5','E6',\n",
    "               'D1','D2','D3','D4','D5','D6','D7',\n",
    "               'C1','C2','C3','C4','C5','C6','C7','C8',\n",
    "               'B1','B2','B3','B4','B5','B6','B7','B8','B9','B10', \n",
    "               'A1','A2','A3','A4','A5','A6','A7','A8','A9','A10']\n",
    "        lst_d = [0] * len(lst_e)\n",
    "    else:\n",
    "        lst_e = ['F1','F2','F4','F5','F6','F7','F8','F9','F10',\n",
    "               'E1','E2','E3','E4','E5','E6','E7','E8','E9','E10', \n",
    "               'D1','D2','D3','D4','D5','D6','D7','D8','D9','D10', \n",
    "               'C3','C4','C5','C6','C7','C8','C9','C10', \n",
    "               'B1','B3','B4','B5','B6','B7','B8','B9','B10', \n",
    "               'A1','A2','A3','A4','A5','A6','A7','A8','A9','A10']\n",
    "        lst_d = [0] * len(lst_e)\n",
    "    lst_s = [subj] * len(lst_e)\n",
    "    \n",
    "    df_o = df_o[df_o.electrode1.isin(lst_e)]\n",
    "    \n",
    "    df_o['distance_to_implant'] = lst_d\n",
    "    df_o['subject'] = lst_s\n",
    "    \n",
    "    df = pd.concat([df, df_o])\n",
    "data_single = data_single.merge(df, how = 'inner', on = ['electrode1','subject'])\n",
    "\n",
    "\n",
    "index_lst = []\n",
    "for i in range(len(data_double)):\n",
    "    if not (data_single[(data_single['subject'] == data_double.subject[i]) & (data_single['electrode1'] == data_double.electrode1[i]) & (data_single['freq'] == data_double.freq[i]) & (data_single['amp1'] == data_double.amp1[i])].empty):\n",
    "        if not (data_single[(data_single['subject'] == data_double.subject[i]) & (data_single['electrode1'] == data_double.electrode2[i]) & (data_single['freq'] == data_double.freq[i]) & (data_single['amp1'] == data_double.amp1[i])].empty):\n",
    "            index_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed4688-5f8d-459a-8ec7-e044f75acbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['MultiElectrode']\n",
    "df_AllSub = pd.DataFrame()\n",
    "\n",
    "for label in range(1):\n",
    "    data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "    data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "    lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "    lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    double = []\n",
    "    single_dtf = []\n",
    "    single_dti = []\n",
    "    lst_subject = []\n",
    "        \n",
    "    distance = []\n",
    "    amp = []\n",
    "    freq = []\n",
    "    between = []\n",
    "    along_1 = []\n",
    "    along_2 = []\n",
    "    between_1 = []\n",
    "    between_2 = []\n",
    "    side = []\n",
    "    \n",
    "    across = []\n",
    "    along = []\n",
    "    electrode = []\n",
    "    electrode_pair = []\n",
    "    for i in range(len(lst)):\n",
    "        electrode1 = lst.electrode1[i]\n",
    "        electrode2 = lst.electrode2[i]\n",
    "        temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        close_electrode = too_close(temp1.subject[0], delta_y=100, delta_rot=5)\n",
    "        close_electrode = []\n",
    "        \n",
    "        if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "            if electrode1 not in close_electrode and electrode2 not in close_electrode:\n",
    "                count = 0\n",
    "                for j in range(len(double_temp)):\n",
    "                    count += double_temp['num_regions'][j]\n",
    "                double.append(count/len(double_temp))\n",
    "                single_dtf.append((temp1.distance_to_fovea[0] + temp2.distance_to_fovea[0])/2)\n",
    "                single_dti.append((temp1.distance_to_implant[0] + temp2.distance_to_implant[0])/2)\n",
    "                lst_subject.append(temp1.subject[0])\n",
    "\n",
    "                subject = shapes.subject_params[temp1.subject[0]]\n",
    "                implant,model = shapes.model_from_params(subject)\n",
    "\n",
    "                arr = dist_across_along([electrode1], [electrode2], implant, model,strategy='radial')\n",
    "                across.append(arr[0,1])\n",
    "                along.append(arr[0,2])\n",
    "\n",
    "                electrode_pair.append(electrode1 + '_' + electrode2)\n",
    "                amp.append(lst.amp1[i])\n",
    "                freq.append(lst.freq[i])\n",
    "\n",
    "        df_investigate = pd.DataFrame({\n",
    "                                           'double':double, \n",
    "                                           'freq':freq,\n",
    "                                           'amp':amp,\n",
    "                                            'across':across,\n",
    "                                            'along':along,\n",
    "                                            'electrode_pair':electrode_pair,\n",
    "                                           'single_dtf':single_dtf,\n",
    "                                           'single_dti':single_dti,\n",
    "                                           'subject':lst_subject\n",
    "                                          })\n",
    "        for subj in ['12-005', '51-009', '52-001']:\n",
    "            df_investigate_temp = df_investigate[df_investigate.subject == subj]\n",
    "            filename = subj + label_list[label]\n",
    "            df_investigate_temp.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')\n",
    "        filename = label_list[label]\n",
    "        df_investigate.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')\n",
    "\n",
    "    df_AllSub = df_investigate.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce8c03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_AllSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f87ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AllSub = df_AllSub[df_AllSub.amp <= 2].reset_index(drop=True)\n",
    "df_investigate = df_investigate[df_investigate.amp <= 2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8273cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_AllSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55e7a5-3921-4a77-8e6c-85b6d232dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2.5\n",
    "\n",
    "\n",
    "removed_indices = []\n",
    "total_len = 0\n",
    "copy = df_investigate.copy()\n",
    "df_AllSub = df_investigate.copy()\n",
    "df_s = pd.DataFrame({})\n",
    "for subj in ['12-005','51-009','52-001','All']:\n",
    "    if subj != 'All': df_t = copy[copy.subject == subj].reset_index(drop=True)\n",
    "    else: df_t = copy.copy()\n",
    "    \n",
    "    if subj != '12-005' and subj != 'All': total_len += len(df_t)\n",
    "    \n",
    "    df_t['amp'] = (df_t['amp'] - df_t['amp'].mean()) / df_t['amp'].std()\n",
    "    df_t['single_dti'] = (df_t['single_dti'] - df_t['single_dti'].mean()) / df_t['single_dti'].std()\n",
    "    df_t['single_dtf'] = (df_t['single_dtf'] - df_t['single_dtf'].mean()) / df_t['single_dtf'].std()\n",
    "    df_t['across'] = (df_t['across'] - df_t['across'].mean()) / df_t['across'].std()\n",
    "    df_t['along'] = (df_t['along'] - df_t['along'].mean()) / df_t['along'].std()\n",
    "    \n",
    "    \n",
    "    if subj != 'All': \n",
    "        before_filtering = set(df_t.index)\n",
    "        df_t = df_t.fillna(0)\n",
    "        df_t = df_t[(abs(df_t.amp) <threshold) & \n",
    "                    (abs(df_t.single_dti) < threshold) & (abs(df_t.single_dtf) < threshold) &\n",
    "                   (abs(df_t.across) < threshold) & (abs(df_t.along) < threshold)]\n",
    "\n",
    "        removed_indices.extend([x + total_len for x in list(before_filtering - set(df_t.index))])\n",
    "        df_s = pd.concat([df_s, df_t])\n",
    "        df_s = df_s.fillna(0)\n",
    "    else: df_AllSub = df_t.copy()\n",
    "        \n",
    "df_investigate = df_s.copy().reset_index(drop=True)\n",
    "df_AllSub = df_AllSub.reset_index(drop=True).drop(removed_indices).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40928e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 2.5\n",
    "# df_AllSub = df_AllSub[(df_AllSub.amp <threshold) & (df_AllSub.across < threshold) \n",
    "#                       & (df_AllSub.single_dtf < threshold) \n",
    "#                       & (df_AllSub.along < threshold)].reset_index(drop=True)\n",
    "# df_investigate = df_investigate[(df_investigate.amp <threshold) \n",
    "#                                 & (df_investigate.single_dtf < threshold) \n",
    "#                                 & (df_investigate.across < threshold) \n",
    "#                                 & (df_investigate.along < threshold)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_investigate), len(df_AllSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs= plt.subplots(ncols=5, figsize=(35, 7))\n",
    "# column_lst = ['amp','single_dti', 'single_dtf','across','along']\n",
    "# name_lst = ['Amplitude','Electrode-Retina Distance', 'Electrode-Fovea Distance','Between-Axon Distance','Along-Axon Distance']\n",
    "# for dv in range(5):\n",
    "#     reg = LinearRegression().fit(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]], df_AllSub[['double']])\n",
    "#     y_predicted = reg.predict(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     y = df_AllSub[['double']]-y_predicted\n",
    "\n",
    "#     reg = LinearRegression().fit(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]], df_AllSub[column_lst[dv]])\n",
    "#     y_predicted = reg.predict(df_AllSub[column_lst[:dv] + column_lst[dv+1 :]])\n",
    "#     x = df_AllSub[column_lst[dv]]-y_predicted\n",
    "#     df_AllSub['x'] = x\n",
    "#     df_AllSub['y'] = y\n",
    "#     subject = ['12-005','51-009','52-001']\n",
    "#     marker_lst = ['o','s','^']\n",
    "#     color_lst = ['#1E88E5', '#FFC107','#004D40']\n",
    "#     for i in range(len(subject)):\n",
    "#         temp = df_AllSub[df_AllSub.subject == subject[i]]\n",
    "#         axs[dv].plot(temp['x'],temp['y'],marker_lst[i], color=color_lst[i],alpha=0.6,markersize=13)\n",
    "# #     axs[dv].legend(subject, loc='upper right',prop={'size': 20})\n",
    "#     reg = LinearRegression().fit(np.array(x).reshape(-1,1),np.array(y).reshape(-1,1))\n",
    "#     y_pred = reg.predict(np.array(x).reshape(-1,1))\n",
    "#     axs[dv].plot(x, y_pred,'-', color=\"black\",linewidth=2)\n",
    "#     axs[dv].set(xlabel = name_lst[dv],ylim=(-0.8,1.5),xlim=(-1.8,3.4))\n",
    "#     axs[0].set(ylabel = 'Number of Phosphenes')\n",
    "#     axs[dv].tick_params(axis='both',  labelsize=18)\n",
    "    \n",
    "# #     if dv>0:\n",
    "# #         axs[dv].get_yaxis().set_visible(False)\n",
    "#     axs[dv].yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    \n",
    "#     for item in ([axs[dv].xaxis.label, axs[dv].yaxis.label]):\n",
    "#         item.set_fontsize(30)\n",
    "# #     for item in range(1):\n",
    "# #         axs[dv].set_xticklabels(labels = '', fontsize=18)\n",
    "# fig.savefig('/home/yuchen/paper/12f. Double-Electrode Number of Phosphenes.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n",
    "subject = ['12-005','51-009','52-001']\n",
    "marker_lst = ['o','s','^']\n",
    "color_lst = ['#1E88E5', '#FFC107','#004D40']\n",
    "\n",
    "temp = df_AllSub.copy().reset_index(drop=True)\n",
    "temp = temp.drop(['freq'], axis=1)\n",
    "temp['double'] = (temp['double'])\n",
    "\n",
    "# ======================amp===================================\n",
    "mdf1 = MixedLM.from_formula('double ~ single_dtf + single_dti + across + along', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('amp ~ single_dtf + single_dti + across + along', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[0].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=85)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[0].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "\n",
    "# # =====================single_dtf====================================\n",
    "mdf1 = MixedLM.from_formula('double ~ amp + single_dti + across + along', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('single_dtf ~ amp +  single_dti + across + along', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[1].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=85)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[1].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "\n",
    "# # ========================single_dti=================================\n",
    "# mdf1 = MixedLM.from_formula('double ~ amp + single_dtf + across + along', data=temp, groups=temp['subject']).fit()\n",
    "# mdf2 = MixedLM.from_formula('single_dti ~ amp + single_dtf + across + along', data=temp, groups=temp['subject']).fit()\n",
    "# for i in range(3):\n",
    "#     idx = temp[temp.subject == subject[i]].index\n",
    "#     axes[2].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=85)\n",
    "# reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "# y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "# axes[2].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "      \n",
    "# ========================across=================================\n",
    "mdf1 = MixedLM.from_formula('double ~ amp + single_dtf + single_dti + along', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('across ~ amp + single_dtf + single_dti + along', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[2].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=85)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[2].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "   \n",
    "# ========================along=================================\n",
    "mdf1 = MixedLM.from_formula('double ~ amp + single_dtf + single_dti + across', data=temp, groups=temp['subject']).fit()\n",
    "mdf2 = MixedLM.from_formula('along ~ amp + single_dtf + single_dti + across', data=temp, groups=temp['subject']).fit()\n",
    "for i in range(3):\n",
    "    idx = temp[temp.subject == subject[i]].index\n",
    "    axes[3].scatter(mdf2.resid[idx],mdf1.resid[idx], marker=marker_lst[i],color=color_lst[i],alpha=0.6,s=85)\n",
    "reg = LinearRegression().fit(np.array(mdf2.resid).reshape(-1,1),np.array(mdf1.resid).reshape(-1,1))\n",
    "y_pred = reg.predict(np.array(mdf2.resid).reshape(-1,1))\n",
    "axes[3].plot(mdf2.resid, y_pred,'-', color=\"black\",linewidth=2)\n",
    "   \n",
    "axes[0].set(ylabel='Number of Phosphenes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "        axes[i].get_xaxis().set_visible(True)\n",
    "        axes[i].get_yaxis().set_visible(True)\n",
    "        axes[i].set(ylim=(-0.9,1.5))\n",
    "        axes[i].yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "        axes[i].xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis='both', which='major', labelsize=13)    \n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "axes[0].set_ylabel('Number of Phosphenes', fontsize=21)\n",
    "\n",
    "axes[0].set_xlabel('Amplitude', fontsize=21)\n",
    "axes[1].set_xlabel('Electrode-Fovea Distance', fontsize=21)\n",
    "# axes[2].set_xlabel('Electrode-Retina Distance', fontsize=21)\n",
    "axes[2].set_xlabel('Between-Axon Distance', fontsize=21)\n",
    "axes[3].set_xlabel('Along-Axon Distance', fontsize=21)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('/home/yuchen/shapes/figures/phosnum_ppcor.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # temp = df_investigate.copy().drop(['freq','electrode_pair'],axis=1)\n",
    "\n",
    "# for subj in ['12-005', '51-009', '52-001']:\n",
    "#     temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    \n",
    "#     if subj == '12-005':\n",
    "#         X1 = temp[['amp','single_dtf','single_dti']]\n",
    "#         X1_2 = sm.add_constant(X1)\n",
    "#         X2 = temp[['amp','single_dtf','single_dti','along']]\n",
    "#         X2_2 = sm.add_constant(X2)\n",
    "#         X3 = temp[['amp','single_dtf','single_dti', 'across','along']]\n",
    "#         X3_2 = sm.add_constant(X3)\n",
    "#     else:\n",
    "#         X1 = temp[['amp','single_dtf']]\n",
    "#         X1_2 = sm.add_constant(X1)\n",
    "#         X2 = temp[['amp','single_dtf','along']]\n",
    "#         X2_2 = sm.add_constant(X2)\n",
    "#         X3 = temp[['amp','single_dtf', 'along','across' ]]\n",
    "#         X3_2 = sm.add_constant(X3)\n",
    "        \n",
    "#     y = (temp.double)\n",
    "#     model1 = sm.OLS(y, X1_2)\n",
    "#     model1 = model1.fit()\n",
    "    \n",
    "#     y = (temp.double)\n",
    "#     model2 = sm.OLS(y, X2_2)\n",
    "#     model2 = model2.fit()\n",
    "#     y = (temp.double)\n",
    "#     model3 = sm.OLS(y, X3_2)\n",
    "#     model3 = model3.fit()\n",
    "    \n",
    "#     print(subj)\n",
    "#     anovaResults = anova_lm(model1, model2,model3)\n",
    "#     print(anovaResults)\n",
    "# #     anovaResults = anova_lm(model1, model3)\n",
    "# #     print(anovaResults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c5a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in ['12-005','51-009','52-001']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == '12-005':\n",
    "        X1 = temp[['amp','single_dtf','single_dti']]\n",
    "        X1_2 = sm.add_constant(X1)\n",
    "        X2 = temp[['amp','single_dtf','single_dti','along']]\n",
    "        X2_2 = sm.add_constant(X2)\n",
    "        X3 = temp[['amp','single_dtf','single_dti', 'across']]\n",
    "        X3_2 = sm.add_constant(X3)\n",
    "    elif subj == '51-009':\n",
    "        X1 = temp[['single_dtf']]\n",
    "        X1_2 = sm.add_constant(X1)\n",
    "        X2 = temp[['single_dtf','along']]\n",
    "        X2_2 = sm.add_constant(X2)\n",
    "        X3 = temp[['single_dtf', 'across']]\n",
    "        X3_2 = sm.add_constant(X3)\n",
    "    else:\n",
    "        X1 = temp[['amp','single_dtf']]\n",
    "        X1_2 = sm.add_constant(X1)\n",
    "        X2 = temp[['amp','single_dtf','along']]\n",
    "        X2_2 = sm.add_constant(X2)\n",
    "        X3 = temp[['amp','single_dtf','across']]\n",
    "        X3_2 = sm.add_constant(X3)\n",
    "    \n",
    "        \n",
    "    y = (temp.double)\n",
    "    model1 = sm.OLS(y, X1_2)\n",
    "    model1 = model1.fit()\n",
    "    \n",
    "    y = (temp.double)\n",
    "    model2 = sm.OLS(y, X2_2)\n",
    "    model2 = model2.fit()\n",
    "    y = (temp.double)\n",
    "    model3 = sm.OLS(y, X3_2)\n",
    "    model3 = model3.fit()\n",
    "    print(subj)\n",
    "#     print(round(model1.aic, 3),round(model1.bic, 3),model1.rsquared_adj)\n",
    "    print(round(model2.aic, 3),round(model2.bic, 3),model2.rsquared_adj)\n",
    "    print(round(model3.aic, 3),round(model3.bic, 3),model3.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_investigate.copy().drop(['freq','electrode_pair'],axis=1)\n",
    "temp['double'] = (temp['double'])\n",
    "md1 = MixedLM.from_formula('double ~ amp + single_dtf + single_dti + along', data=temp, \n",
    "                                     groups=temp['subject'])\n",
    "mdf1 = md1.fit(reml=False)\n",
    "# print(mdf.summary())\n",
    "print('double ~ amp + single_dtf + single_dti + along:',round(mdf1.aic,3),round(mdf1.bic,3))\n",
    "\n",
    "temp = df_investigate.copy().drop(['freq','electrode_pair'],axis=1)\n",
    "temp['double'] = (temp['double'])\n",
    "md2 = MixedLM.from_formula('double ~ amp + single_dtf + single_dti + across ', data=temp, \n",
    "                                     groups=temp['subject'])\n",
    "mdf2 = md2.fit(reml=False)\n",
    "# print(mdf.summary())\n",
    "print('double ~ amp + single_dtf + single_dti + across:', round(mdf2.aic,3),round(mdf2.bic,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_investigate.to_csv('/home/yuchen/df_investigate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dc49a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AllSub.to_csv('/home/yuchen/df_AllSub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d725f05-c082-416f-8542-6dafc68d2c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_lst = []\n",
    "attribute = 'phos_num'\n",
    "qq_label = 0\n",
    "\n",
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == '12-005':\n",
    "        X = temp[['amp','single_dtf','single_dti','across', 'along']]\n",
    "    elif subj == 'AllSubjects':\n",
    "        temp = df_investigate.copy().drop(['freq','electrode_pair'],axis=1)\n",
    "        X = temp[['amp','single_dtf','single_dti','across', 'along','subject']]\n",
    "    elif subj == '51-009':\n",
    "        X = temp[['single_dtf','across', 'along']]\n",
    "    else:\n",
    "        X = temp[['amp','single_dtf','across', 'along']]\n",
    "        \n",
    "    if subj == 'AllSubjects':\n",
    "        temp['double'] = (temp['double'])\n",
    "        md = MixedLM.from_formula('double ~ amp + single_dtf + single_dti + across + along', data=temp, \n",
    "                                     groups=temp['subject'])\n",
    "        mdf = md.fit()\n",
    "        print(mdf.summary())\n",
    "        features = temp.drop(['double'], axis=1)\n",
    "        label = temp['double']\n",
    "        print(normal_errors_assumption(mdf, features, label))\n",
    "        print('\\nvariance inflation factor: ')\n",
    "        features = features.drop(['subject'], axis=1)\n",
    "\n",
    "        X = temp[['amp' , 'single_dtf' , 'single_dti' , 'across' , 'along']]\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)] for i in range(len(X.columns))])\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ single_dtf + single_dti + across + along', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('amp ~ single_dtf + single_dti + across + along', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'amp1', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                             mdf.params['amp'], mdf.pvalues['amp']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dti + across + along', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('single_dtf ~ amp +  single_dti + across + along', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dtf', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dtf'], mdf.pvalues['single_dtf']]))\n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dtf + across + along', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('single_dti ~ amp + single_dtf + across + along', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'single_dti', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['single_dti'], mdf.pvalues['single_dti']]))\n",
    "        \n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dtf + single_dti + along', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('across ~ amp + single_dtf + single_dti + along', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'across', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['across'], mdf.pvalues['across']]))\n",
    "        \n",
    "        # =========================================================\n",
    "        mdf1 = MixedLM.from_formula('double ~ amp + single_dtf + single_dti + across', data=temp, groups=temp['subject']).fit()\n",
    "        mdf2 = MixedLM.from_formula('along ~ amp + single_dtf + single_dti + across', data=temp, groups=temp['subject']).fit()\n",
    "        summary_lst.append(np.array([attribute, subj, 'along', scipy.stats.pearsonr(mdf1.resid, mdf2.resid)[0], \n",
    "                   mdf.params['along'], mdf.pvalues['along']]))\n",
    "        \n",
    "        plt.figure()\n",
    "        re = calculate_residuals(mdf, features, label)\n",
    "#         plt.scatter(re['Predicted'], re['Residuals'])\n",
    "#         sm.qqplot(calculate_residuals(mdf, features, label)['Residuals'],line='r')\n",
    "        sm.qqplot(mdf.resid,line='r',ax = axes_qq[4, qq_label])\n",
    "\n",
    "    else: \n",
    "        y = (temp.double)\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X2)\n",
    "        est2 = est.fit()\n",
    "        print(subj)\n",
    "        print(est2.summary())\n",
    "        print(normal_errors_assumption(est2, X2, y, p_value_thresh=0.001))\n",
    "        print('\\nvariance inflation factor: ')\n",
    "        print([[X.columns[i],variance_inflation_factor(X.values, i)]\n",
    "                              for i in range(len(X.columns))])\n",
    "        \n",
    "        plt.figure()\n",
    "        re = calculate_residuals(est2, X2, y)\n",
    "#         plt.scatter(re['Predicted'], re['Residuals'])\n",
    "        sm.qqplot(calculate_residuals(est2, X2, y)['Residuals'],line='r',ax = axes_qq[4, qq_label])\n",
    "        X['double'] = (temp.double)\n",
    "        pcorr = X.pcorr()['double']\n",
    "        for name in pcorr.index[:-1]:\n",
    "            summary_lst.append(np.array([attribute, subj, name, pcorr[name], est2.params[name], est2.pvalues[name]]))\n",
    "    qq_label += 1\n",
    "    \n",
    "summary[attribute] = summary_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst__ = []\n",
    "for i in summary.values():\n",
    "    lst__.append(i)\n",
    "df = pd.DataFrame(np.vstack(lst__),columns=['attribute', 'subject', 'predictor','ppcor','coef','p'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = []\n",
    "r = []\n",
    "b = []\n",
    "for i in range(len(df)):\n",
    "    p = float(df['p'][i])\n",
    "    if p < 0.001: sig.append('***')\n",
    "    elif p < 0.01: sig.append('**')\n",
    "    elif p < 0.05: sig.append('*')\n",
    "    else: sig.append('')\n",
    "    r_ = float(df['ppcor'][i])\n",
    "    round_ = 3\n",
    "    if abs(r_)<0.1: round_+=1\n",
    "    if abs(r_)<0.01: round_+=1\n",
    "    if abs(r_)<0.001: round_+=1\n",
    "    if abs(r_)<0.0001: round_=9\n",
    "    temp = str(round(r_, round_)).split(\"0.\")\n",
    "    r.append(temp[0] + '.'+temp[1])\n",
    "    b_ = float(df['coef'][i])\n",
    "    round_ = 3\n",
    "    if abs(b_)<0.1: round_+=1\n",
    "    if abs(b_)<0.01: round_+=1\n",
    "    if abs(b_)<0.001: round_+=1\n",
    "    if abs(b_)<0.0001: round_=9\n",
    "    temp = str(round(b_, round_)).split(\"0.\")\n",
    "    b.append(temp[0] + '.'+temp[1])\n",
    "    \n",
    "df['sig'] = sig\n",
    "df['r'] = r\n",
    "df['b'] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f064f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[['attribute', 'subject', 'predictor', 'b', 'sig', 'r']]\n",
    "b_sig = []\n",
    "corr = []\n",
    "predictor = []\n",
    "for i in range(len(test)):\n",
    "    if test.iloc[i]['predictor'] == 'amp1': predictor.append('amp')\n",
    "    else: predictor.append(test.iloc[i]['predictor'])\n",
    "    if test.iloc[i]['sig'] != str():\n",
    "        b_sig.append('\\textbf{' + test.iloc[i]['b'] + '}$' +  test.iloc[i]['sig'])\n",
    "        corr.append('\\textbf{' + test.iloc[i]['r'] + '}$')\n",
    "    else:\n",
    "        b_sig.append('' + test.iloc[i]['b'] + '$')\n",
    "        corr.append('' + test.iloc[i]['r'] + '$')\n",
    "test['b_sig'] = b_sig\n",
    "test['corr'] = corr\n",
    "test['predictor'] = predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9de44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['p'] = df['p']\n",
    "import statsmodels\n",
    "temp = test[(test.subject=='AllSubjects') & (test.attribute != 'orientation') & \n",
    "            (test.attribute == 'phos_num')].reset_index(drop=True)\n",
    "results,p,_,_ = statsmodels.stats.multitest.multipletests(temp['p'].astype('float32'), method='bonferroni')\n",
    "temp['results'] = results\n",
    "temp['p_corrected'] = p\n",
    "sig = []\n",
    "for i in range(len(temp)):\n",
    "    p = float(temp['p_corrected'][i])\n",
    "    if p < 0.001: sig.append('***')\n",
    "    elif p < 0.01: sig.append('**')\n",
    "    elif p < 0.05: sig.append('*')\n",
    "    else: sig.append('')\n",
    "temp['sig_corrected'] = sig\n",
    "temp[['attribute', 'subject', 'predictor', 'sig_corrected']].sort_values(['predictor'])\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5cb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('/home/yuchen/doubles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9fcaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[(test.attribute=='phos_num') & (test.predictor=='along')][['attribute', 'subject', 'predictor', 'b_sig', 'corr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d792df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[(test.subject=='AllSubjects') & (test.predictor=='single_dti')][['attribute', 'subject', 'predictor', 'b_sig', 'corr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd9684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 14\n",
    "for i in range(6):\n",
    "    for j in range(4):\n",
    "        axes_qq[i, j].set_xlabel('')\n",
    "        axes_qq[i, j].set_ylabel('')  \n",
    "        \n",
    "axes_qq[0,0].set_ylabel('Area', fontsize=fontsize)  \n",
    "axes_qq[1,0].set_ylabel('Perimeter', fontsize=fontsize)  \n",
    "axes_qq[2,0].set_ylabel('Data Quantiles\\n\\nMajor Axis Length', fontsize=fontsize)  \n",
    "axes_qq[3,0].set_ylabel('Minor Axis Length', fontsize=fontsize)  \n",
    "axes_qq[4,0].set_ylabel('Phosphene Number', fontsize=fontsize)  \n",
    "axes_qq[5,0].set_ylabel('Orientation', fontsize=fontsize)  \n",
    "\n",
    "axes_qq[-1,0].set_xlabel('Subject 1', fontsize=fontsize)  \n",
    "axes_qq[-1,1].set_xlabel('Subject 2\\n\\n Theoretical Quantiles', fontsize=fontsize)  \n",
    "axes_qq[-1,2].set_xlabel('Subject 3', fontsize=fontsize)  \n",
    "axes_qq[-1,3].set_xlabel('All Subjects', fontsize=fontsize)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45912e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_qq.savefig('/home/yuchen/shapes/figures/double_qq.pdf', transparent=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0bf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77533277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d2e40af-9b51-4144-bff2-6ddcc760ac98",
   "metadata": {},
   "source": [
    "## 2. pair_electrode shape = single_electrode shape + single_electrode shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f81d9-9ae2-4fe0-ab08-e5e61d81f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate shapes \n",
    "data = shapes.load_shapes(\"/home/yuchen/shapes/data/shapes.h5\", subjects=['12-005','51-009','52-001'],stim_class=None)\n",
    "\n",
    "\n",
    "result = pd.DataFrame({})\n",
    "for i in range(len(data)):\n",
    "    label_img = skimage.measure.label(data['image'][i]>0)\n",
    "    regions = regionprops(label_img)\n",
    "    props = regionprops_table(label_img, properties=('centroid',\n",
    "                                                     'orientation',\n",
    "                                                     'major_axis_length',\n",
    "                                                     'minor_axis_length',\n",
    "                                                     'area',\n",
    "                                                    'eccentricity',\n",
    "                                                    'perimeter'))\n",
    "    df = pd.DataFrame(props).astype('object')\n",
    "    df.at[0,'centroid-0'] = df.iloc[:, 0].tolist()  # store centroid-x\n",
    "    df.at[0,'centroid-1'] = df.iloc[:, 1].tolist()  # store centroid-y\n",
    "    df.at[0,'orientation'] = df.iloc[:, 2].tolist()  # store orientation\n",
    "    df.at[0,'major_axis_length'] = df.iloc[:, 3].tolist()  # major\n",
    "    df.at[0,'minor_axis_length'] = df.iloc[:, 4].tolist()  # minor\n",
    "    df.at[0,'area'] = df.iloc[:, 5].tolist()  # area\n",
    "    df.at[0,'eccentricity'] = df.iloc[:, 6].tolist()  \n",
    "    df.at[0,'perimeter'] = df.iloc[:, 7].tolist()  \n",
    "    result = pd.concat([result, df.iloc[:1,:]],axis=0)\n",
    "\n",
    "result = result.rename(columns={\"area\":\"size\", \"orientation\":\"orientation_new\", \"eccentricity\":\"eccentricity_new\" })\n",
    "data = pd.concat([data,result.reset_index(drop=True)],axis=1)\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72159ccd-0818-4788-9122-178848243d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_copy.copy()\n",
    "\n",
    "# data_double = data[(data['electrode2'] != str())].reset_index(drop=True)\n",
    "data_single = data[(data['electrode2'] == str())].reset_index(drop=True)\n",
    "data_double = double_recreated.copy()\n",
    "\n",
    "data_single['stim_class'] ='SingleElectrode'\n",
    "df = data_single[['subject', 'electrode1', 'freq', 'amp1']].drop_duplicates().reset_index(drop=True)\n",
    "lst = []\n",
    "lst_size = []\n",
    "lst_major = []\n",
    "lst_minor = []\n",
    "lst_eccentricity = []\n",
    "lst_orientation = []\n",
    "lst_perimeter = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df_temp = data_single[(data_single['subject'] == df.subject[i]) & (data_single['electrode1'] == df.electrode1[i]) & (data_single['freq'] == df.freq[i]) & (data_single['amp1'] == df.amp1[i])].reset_index(drop=True)\n",
    "    ratio = len(df_temp[df_temp['num_regions']>1]) /len(df_temp)\n",
    "    \n",
    "    for row in range(len(df_temp)):\n",
    "        df_temp['size'][row] = sum(df_temp['size'][row])\n",
    "        df_temp['major_axis_length'][row] = sum(df_temp['major_axis_length'][row])\n",
    "        df_temp['minor_axis_length'][row] = sum(df_temp['minor_axis_length'][row])\n",
    "        df_temp['perimeter'][row] = sum(df_temp['perimeter'][row])\n",
    "        df_temp['orientation_new'][row] = sum(df_temp['orientation_new'][row])\n",
    "        \n",
    "    \n",
    "    count_length = len(df_temp)\n",
    "    \n",
    "    lst_size.append(df_temp['size'].sum()/count_length)\n",
    "    lst_major.append(df_temp['major_axis_length'].sum()/count_length)\n",
    "    lst_minor.append(df_temp['minor_axis_length'].sum()/count_length)\n",
    "    lst_perimeter.append(df_temp['perimeter'].sum()/count_length)\n",
    "    lst_orientation.append(df_temp['orientation_new'].sum()/count_length)\n",
    "    \n",
    "        \n",
    "df['avg_size'] = lst_size\n",
    "df['avg_major'] = lst_major\n",
    "df['avg_minor'] = lst_minor\n",
    "df['avg_perimeter'] = lst_perimeter\n",
    "df['avg_orientation'] = lst_orientation\n",
    "\n",
    "\n",
    "data_single = df.copy()\n",
    "\n",
    "index_lst = []\n",
    "for i in range(len(data_double)):\n",
    "    if not (data_single[(data_single['subject'] == data_double.subject[i]) & (data_single['electrode1'] == data_double.electrode1[i]) & (data_single['freq'] == data_double.freq[i]) & (data_single['amp1'] == data_double.amp1[i])].empty):\n",
    "        if not (data_single[(data_single['subject'] == data_double.subject[i]) & (data_single['electrode1'] == data_double.electrode2[i]) & (data_single['freq'] == data_double.freq[i]) & (data_single['amp1'] == data_double.amp1[i])].empty):\n",
    "            index_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf8a8c4-230d-49c8-a097-cfe66a77595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = ['12-005','51-009','52-001']\n",
    "df_dti = pd.DataFrame({})\n",
    "for subj in subject:\n",
    "    lst_e = []\n",
    "    lst_dtf = []\n",
    "\n",
    "    s = shapes.subject_params[subj]\n",
    "    implant,model = shapes.model_from_params(s)\n",
    "    for i in string.ascii_uppercase[0:6]: \n",
    "        for j in range(1,11):\n",
    "            electrode = i + str(j)\n",
    "            lst_e.append(electrode)\n",
    "            lst_dtf.append(math.sqrt(implant[electrode].x**2 +implant[electrode].y**2 ))\n",
    "\n",
    "    df_o = pd.DataFrame(lst_e, columns=['electrode1'])\n",
    "    df_o['distance_to_fovea'] = lst_dtf\n",
    "\n",
    "    if subj == '12-005':\n",
    "        lst_d = [0,0,0,2,7,7,0,0,5,0,\n",
    "                    0,0,4,11,13,15,15,3,7,4,\n",
    "                    0,0,15,16,17,17,19,16,9,4,\n",
    "                    0,0,16,19,15,17,22,25,13,10,\n",
    "                    0,0,8,15,14,13,17,23,14,2,\n",
    "                    0,0,10,15,13,12,9,11,5]\n",
    "        lst_e = lst_e[:-1]\n",
    "    elif subj == '51-009':\n",
    "        lst_e = ['F1','F2','F3','F4','F5','F6',\n",
    "               'E1','E2','E3','E4','E5','E6',\n",
    "               'D1','D2','D3','D4','D5','D6','D7',\n",
    "               'C1','C2','C3','C4','C5','C6','C7','C8',\n",
    "               'B1','B2','B3','B4','B5','B6','B7','B8','B9','B10', \n",
    "               'A1','A2','A3','A4','A5','A6','A7','A8','A9','A10']\n",
    "        \n",
    "        lst_d = [0] * len(lst_e)\n",
    "    else:\n",
    "        lst_e = ['F1','F2','F4','F5','F6','F7','F8','F9','F10',\n",
    "                   'E1','E2','E3','E4','E5','E6','E7','E8','E9','E10', \n",
    "                   'D1','D2','D3','D4','D5','D6','D7','D8','D9','D10', \n",
    "                   'C3','C4','C5','C6','C7','C8','C9','C10', \n",
    "                   'B1','B3','B4','B5','B6','B7','B8','B9','B10', \n",
    "                   'A1','A2','A3','A4','A5','A6','A7','A8','A9','A10']\n",
    "        lst_d = [0] * len(lst_e)\n",
    "    lst_s = [subj] * len(lst_e)\n",
    "\n",
    "    df_o = df_o[df_o.electrode1.isin(lst_e)]\n",
    "    df_o['distance_to_implant'] = lst_d\n",
    "    df_o['subject'] = lst_s\n",
    "    df_dti = pd.concat([df_dti, df_o])\n",
    "df_dti = df_dti.reset_index(drop=True)\n",
    "\n",
    "data_single = data_single.merge(df_dti, how = 'inner', on = ['electrode1','subject'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28909e4c-7a2d-45c9-a79b-87249414f447",
   "metadata": {},
   "source": [
    "### size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3cb00-5e1e-49bf-91dd-a52a39f973b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['MultiElectrode']\n",
    "for label in range(1):\n",
    "    data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "    data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "    lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "    lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "    double = []\n",
    "    single = []\n",
    "    single1 = []\n",
    "    single2 = []\n",
    "    lst_subject = []\n",
    "    electrode_pair = []\n",
    "        \n",
    "    distance = []\n",
    "    distance_tan = []\n",
    "    distance_per = []\n",
    "    same_side = []   # check if both electrodes are at the same side of raphe, 1 for true, 0 for false\n",
    "    within_range = []  # check if electrode is within 2mm of fovea, 1 for true, 0 for false\n",
    "    between = []\n",
    "    along = []\n",
    "    amp = []\n",
    "    freq = []\n",
    "    electrode = []\n",
    "    inside = []\n",
    "    single_dti = []\n",
    "    single_dtf=[]\n",
    "    for i in range(len(lst)):\n",
    "        electrode1 = lst.electrode1[i]\n",
    "        electrode2 = lst.electrode2[i]\n",
    "        temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "            count = 0\n",
    "            for j in range(len(double_temp)):\n",
    "                count += sum(double_temp['size'][j])\n",
    "            double.append(count/len(double_temp))\n",
    "            single.append(temp1.avg_size[0] + temp2.avg_size[0])\n",
    "            single1.append(temp1.avg_size[0])\n",
    "            single2.append(temp2.avg_size[0])\n",
    "            \n",
    "            lst_subject.append(temp1.subject[0])\n",
    "                \n",
    "            subject = shapes.subject_params[temp1.subject[0]]\n",
    "            implant,model = shapes.model_from_params(subject)\n",
    "                \n",
    "            e1_x = implant[electrode1].x\n",
    "            e1_y = implant[electrode1].y\n",
    "            e2_x = implant[electrode2].x\n",
    "            e2_y = implant[electrode2].y\n",
    "            \n",
    "            single_dti.append(mean([df_dti[(df_dti.electrode1 == lst.electrode1[i]) & \n",
    "                                           (df_dti.subject == lst.subject[i])].distance_to_implant.tolist()[0], \n",
    "                                    df_dti[(df_dti.electrode1 == lst.electrode2[i]) & \n",
    "                                           (df_dti.subject == lst.subject[i])].distance_to_implant.tolist()[0]]))\n",
    "            \n",
    "            \n",
    "            distance.append(math.sqrt((e1_x - e2_x)**2 + (e1_y - e2_y)**2))\n",
    "            single_dtf.append(mean([math.sqrt(e1_x**2 + e1_y**2), math.sqrt(e2_x**2 + e2_y**2)]))\n",
    "            \n",
    "            amp.append(lst.amp1[i])\n",
    "            freq.append(lst.freq[i])\n",
    "            electrode_pair.append(electrode1 + str('_') + electrode2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_investigate = pd.DataFrame({    'single':single,\n",
    "                                   'single1':single1,\n",
    "                                   'single2':single2,\n",
    "                                       'double':double, \n",
    "                                   'single_dti':single_dti,\n",
    "                                   'single_dtf':single_dtf,\n",
    "\n",
    "                                   'distance':distance,\n",
    "                                   'electrode_pair':electrode_pair,\n",
    "                                       'subject':lst_subject,\n",
    "                                   'amp':amp,\n",
    "                                   'freq':freq\n",
    "                                      })\n",
    "\n",
    "    temp = df_investigate[(df_investigate.amp == 2) & (df_investigate.freq == 20) & \n",
    "                              (df_investigate.single_dti == 0) &\n",
    "                              (df_investigate.single_dtf > 2950) & (df_investigate.single_dtf < 3450)]\n",
    "                          \n",
    "    temp = temp.groupby(['amp','freq','subject']).mean().reset_index()\n",
    "    df = pd.DataFrame({})\n",
    "    for subj in temp.subject:\n",
    "        df_investigate_temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "        df_investigate_temp['single'] = df_investigate_temp['single'] / temp[temp.subject == subj].iloc[0]['single']\n",
    "        df_investigate_temp['double'] = df_investigate_temp['double'] / temp[temp.subject == subj].iloc[0]['single']\n",
    "        df = pd.concat([df, df_investigate_temp])\n",
    "    df_investigate = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a74d7-4812-4ee1-a096-0b34b0156fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == 'AllSubjects':\n",
    "        temp = df_investigate\n",
    "    X = temp[['single']]\n",
    "    y = temp.double\n",
    "#     X2 = sm.add_constant(X)\n",
    "#     est = sm.OLS(y, X2)\n",
    "    est = sm.OLS(y, X)\n",
    "\n",
    "    est2 = est.fit()\n",
    "    print(est2.pvalues)\n",
    "#     print('subject: ' + subj)\n",
    "#     print(est2.summary())\n",
    "#     print('\\ncoefficient with more digits: ')\n",
    "#     print(est2.params)\n",
    "#     print('\\npartial correlation: ')\n",
    "#     print(temp[['single','double']].pcorr())\n",
    "#     print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81421d8-9f41-4cd9-9dfe-839d1287ebb1",
   "metadata": {},
   "source": [
    "### major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e5bef-3531-4861-9dcd-96129d46041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['MultiElectrode']\n",
    "for label in range(1):\n",
    "    data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "    data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "    lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "    lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "    double = []\n",
    "    single = []\n",
    "    single1 = []\n",
    "    single2 = []\n",
    "    lst_subject = []\n",
    "    electrode_pair = []\n",
    "        \n",
    "    distance = []\n",
    "    distance_tan = []\n",
    "    distance_per = []\n",
    "    same_side = []   # check if both electrodes are at the same side of raphe, 1 for true, 0 for false\n",
    "    within_range = []  # check if electrode is within 2mm of fovea, 1 for true, 0 for false\n",
    "    between = []\n",
    "    along = []\n",
    "    amp = []\n",
    "    freq = []\n",
    "    electrode = []\n",
    "    inside = []\n",
    "    single_dti = []\n",
    "    single_dtf=[]\n",
    "    for i in range(len(lst)):\n",
    "        electrode1 = lst.electrode1[i]\n",
    "        electrode2 = lst.electrode2[i]\n",
    "        temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "            count = 0\n",
    "            for j in range(len(double_temp)):\n",
    "                count += sum(double_temp['major_axis_length'][j])\n",
    "            double.append(count/len(double_temp))\n",
    "\n",
    "            single.append(temp1.avg_major[0] + temp2.avg_major[0])\n",
    "            single1.append(temp1.avg_major[0])\n",
    "            single2.append(temp2.avg_major[0])\n",
    "            \n",
    "            lst_subject.append(temp1.subject[0])\n",
    "                \n",
    "            subject = shapes.subject_params[temp1.subject[0]]\n",
    "            implant,model = shapes.model_from_params(subject)\n",
    "                \n",
    "            e1_x = implant[electrode1].x\n",
    "            e1_y = implant[electrode1].y\n",
    "            e2_x = implant[electrode2].x\n",
    "            e2_y = implant[electrode2].y\n",
    "            \n",
    "            single_dti.append(mean([df_dti[(df_dti.electrode1 == lst.electrode1[i]) & \n",
    "                                           (df_dti.subject == lst.subject[i])].distance_to_implant.tolist()[0], \n",
    "                                    df_dti[(df_dti.electrode1 == lst.electrode2[i]) & \n",
    "                                           (df_dti.subject == lst.subject[i])].distance_to_implant.tolist()[0]]))\n",
    "            \n",
    "            distance.append(math.sqrt((e1_x - e2_x)**2 + (e1_y - e2_y)**2))\n",
    "            single_dtf.append(mean([math.sqrt(e1_x**2 + e1_y**2), math.sqrt(e2_x**2 + e2_y**2)]))\n",
    "            \n",
    "            amp.append(lst.amp1[i])\n",
    "            freq.append(lst.freq[i])\n",
    "            electrode_pair.append(electrode1 + '_' + electrode2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_investigate = pd.DataFrame({    'single':single,\n",
    "                                   'single1':single1,\n",
    "                                   'single2':single2,\n",
    "                                       'double':double, \n",
    "                                   'single_dti':single_dti,\n",
    "                                   'single_dtf':single_dtf,\n",
    "\n",
    "                                   'distance':distance,\n",
    "                                   'electrode_pair':electrode_pair,\n",
    "                                       'subject':lst_subject,\n",
    "                                   'amp':amp,\n",
    "                                   'freq':freq\n",
    "                                      })\n",
    "\n",
    "    temp = df_investigate[(df_investigate.amp == 2) & (df_investigate.freq == 20) & \n",
    "                              (df_investigate.single_dti == 0) &\n",
    "                              (df_investigate.single_dtf > 2950) & (df_investigate.single_dtf < 3450)]\n",
    "\n",
    "    temp = temp.groupby(['amp','freq','subject']).mean().reset_index()\n",
    "    df = pd.DataFrame({})\n",
    "    for subj in temp.subject:\n",
    "        df_investigate_temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "        df_investigate_temp['single'] = df_investigate_temp['single'] / temp[temp.subject == subj].iloc[0]['single']\n",
    "        df_investigate_temp['double'] = df_investigate_temp['double'] / temp[temp.subject == subj].iloc[0]['single']\n",
    "        df = pd.concat([df, df_investigate_temp])\n",
    "    df_investigate = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a0693",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'major'\n",
    "df_investigate[['single','double','single_dti','single_dtf','subject','electrode_pair','amp','freq']].to_csv('/home/yuchen/' + name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e51e6-f1dc-4f7f-bf6e-f0a9437aae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == 'AllSubjects':\n",
    "        temp = df_investigate\n",
    "    X = temp[['single']]\n",
    "    y = temp.double\n",
    "    est = sm.OLS(y, X)\n",
    "    \n",
    "#     X2 = sm.add_constant(X)\n",
    "#     est = sm.OLS(y, X2)\n",
    "    est2 = est.fit()\n",
    "    print(est2.pvalues)\n",
    "#     print('subject: ' + subj)\n",
    "#     print(est2.summary())\n",
    "#     print('\\ncoefficient with more digits: ')\n",
    "#     print(est2.params)\n",
    "#     print('\\npartial correlation: ')\n",
    "#     print(temp[['single','double']].pcorr())\n",
    "#     print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dfbef7-dabf-45a4-a9e2-158f2d5bdb7d",
   "metadata": {},
   "source": [
    "### minor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a2968-64ac-4f4b-9f8a-25738eb60a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['MultiElectrode']\n",
    "for label in range(1):\n",
    "    data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "    data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "    lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "    lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "    double = []\n",
    "    single = []\n",
    "    single1 = []\n",
    "    single2 = []\n",
    "    lst_subject = []\n",
    "    electrode_pair = []\n",
    "        \n",
    "    distance = []\n",
    "    distance_tan = []\n",
    "    distance_per = []\n",
    "    same_side = []   # check if both electrodes are at the same side of raphe, 1 for true, 0 for false\n",
    "    within_range = []  # check if electrode is within 2mm of fovea, 1 for true, 0 for false\n",
    "    between = []\n",
    "    along = []\n",
    "    amp = []\n",
    "    freq = []\n",
    "    electrode = []\n",
    "    inside = []\n",
    "    single_dti = []\n",
    "    single_dtf=[]\n",
    "    for i in range(len(lst)):\n",
    "        electrode1 = lst.electrode1[i]\n",
    "        electrode2 = lst.electrode2[i]\n",
    "        temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "            count = 0\n",
    "            for j in range(len(double_temp)):\n",
    "                count += sum(double_temp['minor_axis_length'][j])\n",
    "            double.append(count/len(double_temp))\n",
    "            single.append(temp1.avg_minor[0] + temp2.avg_minor[0])\n",
    "            single1.append(temp1.avg_minor[0])\n",
    "            single2.append(temp2.avg_minor[0])\n",
    "            \n",
    "            lst_subject.append(temp1.subject[0])\n",
    "                \n",
    "            subject = shapes.subject_params[temp1.subject[0]]\n",
    "            implant,model = shapes.model_from_params(subject)\n",
    "                \n",
    "            e1_x = implant[electrode1].x\n",
    "            e1_y = implant[electrode1].y\n",
    "            e2_x = implant[electrode2].x\n",
    "            e2_y = implant[electrode2].y\n",
    "            \n",
    "            amp.append(lst.amp1[i])\n",
    "            freq.append(lst.freq[i])\n",
    "            \n",
    "            single_dti.append(mean([df_dti[(df_dti.electrode1 == lst.electrode1[i]) & \n",
    "                                           (df_dti.subject == lst.subject[i])].distance_to_implant.tolist()[0], \n",
    "                                    df_dti[(df_dti.electrode1 == lst.electrode2[i]) & \n",
    "                                           (df_dti.subject == lst.subject[i])].distance_to_implant.tolist()[0]]))\n",
    "                \n",
    "            \n",
    "            distance.append(math.sqrt((e1_x - e2_x)**2 + (e1_y - e2_y)**2))\n",
    "            single_dtf.append(mean([math.sqrt(e1_x**2 + e1_y**2), math.sqrt(e2_x**2 + e2_y**2)]))\n",
    "            electrode_pair.append(electrode1 + str('_') + electrode2)\n",
    "    \n",
    "    df_investigate = pd.DataFrame({    'single':single,\n",
    "                                   'single1':single1,\n",
    "                                   'single2':single2,\n",
    "                                       'double':double, \n",
    "                                   'single_dti':single_dti,\n",
    "                                   'single_dtf':single_dtf,\n",
    "\n",
    "                                   'distance':distance,\n",
    "                                   'electrode_pair':electrode_pair,\n",
    "                                       'subject':lst_subject,\n",
    "                                   'amp':amp,\n",
    "                                   'freq':freq\n",
    "                                      })\n",
    "\n",
    "    temp = df_investigate[(df_investigate.amp == 2) & (df_investigate.freq == 20) & \n",
    "                              (df_investigate.single_dti == 0) &\n",
    "                              (df_investigate.single_dtf > 2950) & (df_investigate.single_dtf < 3450)]\n",
    "#                           (df_investigate.single_dtf > 2500) & (df_investigate.single_dtf < 5000)]             \n",
    "                          \n",
    "    temp = temp.groupby(['amp','freq','subject']).mean().reset_index()\n",
    "    df = pd.DataFrame({})\n",
    "    for subj in temp.subject:\n",
    "        df_investigate_temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "        df_investigate_temp['single'] = df_investigate_temp['single'] / temp[temp.subject == subj].iloc[0]['single']\n",
    "        df_investigate_temp['double'] = df_investigate_temp['double'] / temp[temp.subject == subj].iloc[0]['single']\n",
    "        df = pd.concat([df, df_investigate_temp])\n",
    "    df_investigate = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'minor'\n",
    "df_investigate[['single','double','single_dti','single_dtf','electrode_pair','subject','amp','freq']].to_csv('/home/yuchen/' + name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4f373-7b4e-4300-833b-9cd81a31bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == 'AllSubjects':\n",
    "        temp = df_investigate\n",
    "    X = temp[['single']]\n",
    "    y = temp.double\n",
    "    est = sm.OLS(y, X)\n",
    "#     X2 = sm.add_constant(X)\n",
    "#     est = sm.OLS(y, X2)\n",
    "    est2 = est.fit()\n",
    "    print(est2.pvalues)\n",
    "    \n",
    "#     print('subject: ' + subj)\n",
    "#     print(est2.summary())\n",
    "#     print('\\ncoefficient with more digits: ')\n",
    "#     print(est2.params)\n",
    "#     print('\\npartial correlation: ')\n",
    "#     print(temp[['single','double']].pcorr())\n",
    "#     print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f161d-e52d-4e2d-9087-f428739e3910",
   "metadata": {},
   "source": [
    "### perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d109b-c239-45c0-93b9-1c117e1357b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['MultiElectrode']\n",
    "for label in range(1):\n",
    "    data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "    data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "    lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "    lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "    double = []\n",
    "    single = []\n",
    "    single1 = []\n",
    "    single2 = []\n",
    "    lst_subject = []\n",
    "    electrode_pair = []\n",
    "    distance = []\n",
    "    distance_tan = []\n",
    "    distance_per = []\n",
    "    between = []\n",
    "    along = []\n",
    "    same_side = []\n",
    "    amp = []\n",
    "    freq = []\n",
    "    inside = []\n",
    "    electrode = []\n",
    "    single_dti = []\n",
    "    single_dtf=[]\n",
    "    for i in range(len(lst)):\n",
    "        electrode1 = lst.electrode1[i]\n",
    "        electrode2 = lst.electrode2[i]\n",
    "        temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "            count = 0\n",
    "            for j in range(len(double_temp)):\n",
    "                count += sum(double_temp['perimeter'][j])\n",
    "            double.append(count/len(double_temp))\n",
    "            single.append(temp1.avg_perimeter[0] + temp2.avg_perimeter[0])\n",
    "            single1.append(temp1.avg_perimeter[0])\n",
    "            single2.append(temp2.avg_perimeter[0])\n",
    "            \n",
    "            lst_subject.append(temp1.subject[0])\n",
    "                \n",
    "            subject = shapes.subject_params[temp1.subject[0]]\n",
    "            implant,model = shapes.model_from_params(subject)\n",
    "                \n",
    "            e1_x = implant[electrode1].x\n",
    "            e1_y = implant[electrode1].y\n",
    "            e2_x = implant[electrode2].x\n",
    "            e2_y = implant[electrode2].y\n",
    "                \n",
    "            amp.append(lst.amp1[i])\n",
    "            freq.append(lst.freq[i])\n",
    "            \n",
    "            electrode_pair.append(electrode1+'_'+electrode2)\n",
    "            \n",
    "            single_dti.append(mean([df_dti[(df_dti.electrode1 == lst.electrode1[i]) & \n",
    "                                           (df_dti.subject == lst.subject[i])].distance_to_implant.tolist()[0], \n",
    "                                    df_dti[(df_dti.electrode1 == lst.electrode2[i]) & \n",
    "                                           (df_dti.subject == lst.subject[i])].distance_to_implant.tolist()[0]]))\n",
    "                \n",
    "            \n",
    "            distance.append(math.sqrt((e1_x - e2_x)**2 + (e1_y - e2_y)**2))\n",
    "            single_dtf.append(mean([math.sqrt(e1_x**2 + e1_y**2), math.sqrt(e2_x**2 + e2_y**2)]))\n",
    "    \n",
    "    \n",
    "    df_investigate = pd.DataFrame({    'single':single,\n",
    "                                   'single1':single1,\n",
    "                                   'single2':single2,\n",
    "                                       'double':double, \n",
    "                                   'single_dti':single_dti,\n",
    "                                   'single_dtf':single_dtf,\n",
    "                                   'electrode_pair':electrode_pair,\n",
    "\n",
    "                                   'distance':distance,\n",
    "                                       'subject':lst_subject,\n",
    "                                   'amp':amp,\n",
    "                                   'freq':freq\n",
    "                                      })\n",
    "\n",
    "    temp = df_investigate[(df_investigate.amp == 2) & (df_investigate.freq == 20) & \n",
    "                              (df_investigate.single_dti == 0) &\n",
    "                              (df_investigate.single_dtf > 2950) & (df_investigate.single_dtf < 3450)]\n",
    "#                           (df_investigate.single_dtf > 2500) & (df_investigate.single_dtf < 5000)]             \n",
    "                       \n",
    "    temp = temp.groupby(['amp','freq','subject']).mean().reset_index()\n",
    "    df = pd.DataFrame({})\n",
    "    for subj in temp.subject:\n",
    "        df_investigate_temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "        df_investigate_temp['single'] = df_investigate_temp['single'] / temp[temp.subject == subj].iloc[0]['single']\n",
    "        df_investigate_temp['double'] = df_investigate_temp['double'] / temp[temp.subject == subj].iloc[0]['single']\n",
    "        df = pd.concat([df, df_investigate_temp])\n",
    "    df_investigate = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'perimeter'\n",
    "df_investigate[['single','double','single_dti','single_dtf','electrode_pair','subject','amp','freq']].to_csv('/home/yuchen/' + name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292421ad-706a-4183-ab6c-2d910b2d7bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == 'AllSubjects':\n",
    "        temp = df_investigate\n",
    "    X = temp[['single']]\n",
    "    y = temp.double\n",
    "    est = sm.OLS(y, X)\n",
    "#     X2 = sm.add_constant(X)\n",
    "#     est = sm.OLS(y, X2)\n",
    "    est2 = est.fit()\n",
    "    print(est2.pvalues)\n",
    "    \n",
    "#     print('subject: ' + subj)\n",
    "#     print(est2.summary())\n",
    "#     print('\\ncoefficient with more digits: ')\n",
    "#     print(est2.params)\n",
    "#     print('\\npartial correlation: ')\n",
    "#     print(temp[['single','double']].pcorr())\n",
    "#     print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa76ce-2dff-4741-9d57-a1d8c490c6f4",
   "metadata": {},
   "source": [
    "### orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570292f-32bb-4eb7-8e00-287615631797",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['MultiElectrode']\n",
    "for label in range(1):\n",
    "    data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "    data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "    lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "    lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "    double = []\n",
    "    single = []\n",
    "    single1 = []\n",
    "    single2 = []\n",
    "    lst_subject = []\n",
    "    between = []\n",
    "    along = []\n",
    "    distance = []\n",
    "    distance_tan = []\n",
    "    distance_per = []\n",
    "    same_side = []\n",
    "    inside = []\n",
    "    amp = []\n",
    "    freq = []\n",
    "    electrode = []\n",
    "    for i in range(len(lst)):\n",
    "        electrode1 = lst.electrode1[i]\n",
    "        electrode2 = lst.electrode2[i]\n",
    "        temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "            count = 0\n",
    "            for j in range(len(double_temp)):\n",
    "                count += mean(double_temp['orientation_new'][j])\n",
    "            double.append(count/len(double_temp))\n",
    "            single.append(mean([temp1.avg_orientation[0], temp2.avg_orientation[0]]))\n",
    "            single1.append(temp1.avg_orientation[0])\n",
    "            single2.append(temp2.avg_orientation[0])\n",
    "            \n",
    "            lst_subject.append(temp1.subject[0])\n",
    "                \n",
    "            subject = shapes.subject_params[temp1.subject[0]]\n",
    "            implant,model = shapes.model_from_params(subject)\n",
    "                \n",
    "            e1_x = implant[electrode1].x\n",
    "            e1_y = implant[electrode1].y\n",
    "            e2_x = implant[electrode2].x\n",
    "            e2_y = implant[electrode2].y\n",
    "\n",
    "            distance.append(math.sqrt((e1_x - e2_x)**2 + (e1_y - e2_y)**2))\n",
    "            \n",
    "            amp.append(lst.amp1[i])\n",
    "            freq.append(lst.freq[i])\n",
    "\n",
    "    df_investigate = pd.DataFrame({    'single':single,\n",
    "                                   'single1':single1,\n",
    "                                   'single2':single2,\n",
    "                                       'double':double, \n",
    "                                   'distance':distance,\n",
    "                                       'subject':lst_subject,\n",
    "                                   'amp':amp,\n",
    "                                   'freq':freq\n",
    "                                      })\n",
    "    for subj in ['12-005', '51-009', '52-001']:\n",
    "        df_investigate_temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "        filename = subj + label_list[label] \n",
    "        df_investigate_temp.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')\n",
    "    filename = label_list[label]\n",
    "    df_investigate.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe97fd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == 'AllSubjects':\n",
    "        temp = df_investigate\n",
    "    X = temp[['single']]\n",
    "    y = temp.double\n",
    "    est = sm.OLS(y, X)\n",
    "    est2 = est.fit()\n",
    "    print('subject: ' + subj)\n",
    "    print(est2.summary())\n",
    "    print('\\ncoefficient with more digits: ')\n",
    "    print(est2.params)\n",
    "    print('\\npartial correlation: ')\n",
    "    print(temp[['single','double']].pcorr())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f92698-c5ec-40c2-9a7e-b6868d3d1467",
   "metadata": {},
   "source": [
    "### phosphene number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_copy.copy()\n",
    "\n",
    "# data_double = data[(data['electrode2'] != str())].reset_index(drop=True)\n",
    "data_double = double_recreated.copy()\n",
    "data_single = data[(data['electrode2'] == str())].reset_index(drop=True)\n",
    "\n",
    "\n",
    "subject = ['12-005','51-009','52-001']\n",
    "df_dti = pd.DataFrame({})\n",
    "for subj in subject:\n",
    "    lst_e = []\n",
    "    lst_dtf = []\n",
    "\n",
    "    s = shapes.subject_params[subj]\n",
    "    implant,model = shapes.model_from_params(s)\n",
    "    for i in string.ascii_uppercase[0:6]: \n",
    "        for j in range(1,11):\n",
    "            electrode = i + str(j)\n",
    "            lst_e.append(electrode)\n",
    "            lst_dtf.append(math.sqrt(implant[electrode].x**2 +implant[electrode].y**2 ))\n",
    "\n",
    "    df_o = pd.DataFrame(lst_e, columns=['electrode1'])\n",
    "    df_o['distance_to_fovea'] = lst_dtf\n",
    "\n",
    "    if subj == '12-005':\n",
    "        lst_d = [0,0,0,2,7,7,0,0,5,0,\n",
    "                    0,0,4,11,13,15,15,3,7,4,\n",
    "                    0,0,15,16,17,17,19,16,9,4,\n",
    "                    0,0,16,19,15,17,22,25,13,10,\n",
    "                    0,0,8,15,14,13,17,23,14,2,\n",
    "                    0,0,10,15,13,12,9,11,5]\n",
    "        lst_e = lst_e[:-1]\n",
    "    elif subj == '51-009':\n",
    "        lst_e = ['F1','F2','F3','F4','F5','F6',\n",
    "               'E1','E2','E3','E4','E5','E6',\n",
    "               'D1','D2','D3','D4','D5','D6','D7',\n",
    "               'C1','C2','C3','C4','C5','C6','C7','C8',\n",
    "               'B1','B2','B3','B4','B5','B6','B7','B8','B9','B10', \n",
    "               'A1','A2','A3','A4','A5','A6','A7','A8','A9','A10']\n",
    "        \n",
    "        lst_d = [0] * len(lst_e)\n",
    "    else:\n",
    "        lst_e = ['F1','F2','F4','F5','F6','F7','F8','F9','F10',\n",
    "                   'E1','E2','E3','E4','E5','E6','E7','E8','E9','E10', \n",
    "                   'D1','D2','D3','D4','D5','D6','D7','D8','D9','D10', \n",
    "                   'C3','C4','C5','C6','C7','C8','C9','C10', \n",
    "                   'B1','B3','B4','B5','B6','B7','B8','B9','B10', \n",
    "                   'A1','A2','A3','A4','A5','A6','A7','A8','A9','A10']\n",
    "        lst_d = [0] * len(lst_e)\n",
    "    lst_s = [subj] * len(lst_e)\n",
    "\n",
    "    df_o = df_o[df_o.electrode1.isin(lst_e)]\n",
    "    df_o['distance_to_implant'] = lst_d\n",
    "    df_o['subject'] = lst_s\n",
    "    df_dti = pd.concat([df_dti, df_o])\n",
    "df_dti = df_dti.reset_index(drop=True)\n",
    "\n",
    "data_single = data_single.merge(df_dti, how = 'inner', on = ['electrode1','subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2edd6-e03e-4c66-9457-95ce06999d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_single['stim_class'] ='SingleElectrode'\n",
    "df = data_single[['subject', 'electrode1', 'freq', 'amp1']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "lst = []\n",
    "lst_phosphene = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df_temp = data_single[(data_single['subject'] == df.subject[i]) & (data_single['electrode1'] == df.electrode1[i]) & (data_single['freq'] == df.freq[i]) & (data_single['amp1'] == df.amp1[i])].reset_index(drop=True)\n",
    "    ratio = len(df_temp[df_temp['num_regions']>1]) /len(df_temp)\n",
    "    lst.append(ratio)\n",
    "    lst_phosphene.append(mean(df_temp['num_regions']))\n",
    "        \n",
    "df['phosphene'] = lst_phosphene\n",
    "\n",
    "data_single = df\n",
    "\n",
    "\n",
    "index_lst = []\n",
    "for i in range(len(data_double)):\n",
    "    if not (data_single[(data_single['subject'] == data_double.subject[i]) & (data_single['electrode1'] == data_double.electrode1[i]) & (data_single['freq'] == data_double.freq[i]) & (data_single['amp1'] == data_double.amp1[i])].empty):\n",
    "        if not (data_single[(data_single['subject'] == data_double.subject[i]) & (data_single['electrode1'] == data_double.electrode2[i]) & (data_single['freq'] == data_double.freq[i]) & (data_single['amp1'] == data_double.amp1[i])].empty):\n",
    "            index_lst.append(i)\n",
    "            \n",
    "label_list = ['MultiElectrode']\n",
    "\n",
    "for label in range(1):\n",
    "    data_double_temp = data_double.iloc[index_lst].reset_index(drop=True)\n",
    "    data_double_temp = data_double_temp[data_double_temp['stim_class'] == label_list[label]]\n",
    "    lst = data_double_temp[['electrode1','electrode2','amp1','freq','subject']]\n",
    "    lst = lst.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    double = []\n",
    "    single = []\n",
    "    single1 = []\n",
    "    single2 = []\n",
    "    electrode_pair = []\n",
    "\n",
    "    lst_subject = []\n",
    "    distance = []\n",
    "    electrode = []\n",
    "\n",
    "    amp = []\n",
    "    freq = []\n",
    "    inside = []\n",
    "    for i in range(len(lst)):\n",
    "        electrode1 = lst.electrode1[i]\n",
    "        electrode2 = lst.electrode2[i]\n",
    "        temp1 = data_single[(data_single['electrode1'] == electrode1) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        temp2 = data_single[(data_single['electrode1'] == electrode2) &  (data_single['subject'] == lst.subject[i])  & (data_single['amp1'] == lst.amp1[i]) & (data_single['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        double_temp = data_double_temp[(data_double_temp['electrode1'] == electrode1) & ((data_double_temp['electrode2'] == electrode2))& (data_double_temp['subject'] == lst.subject[i]) & (data_double_temp['amp1'] == lst.amp1[i]) & (data_double_temp['freq'] == lst.freq[i])].reset_index(drop=True)\n",
    "        if not temp1.empty and not temp2.empty and not double_temp.empty:\n",
    "            count = 0\n",
    "            for j in range(len(double_temp)):\n",
    "                count += double_temp['num_regions'][j]\n",
    "            double.append(count/len(double_temp))\n",
    "            single.append(sum([temp1.phosphene[0], temp2.phosphene[0]]))\n",
    "            single1.append(temp1.phosphene[0])\n",
    "            single2.append(temp2.phosphene[0])\n",
    "            \n",
    "            lst_subject.append(temp1.subject[0])\n",
    "                \n",
    "            subject = shapes.subject_params[temp1.subject[0]]\n",
    "            implant,model = shapes.model_from_params(subject)\n",
    "            \n",
    "            amp.append(lst.amp1[i])\n",
    "            freq.append(lst.freq[i])\n",
    "            electrode_pair.append(electrode1+'_'+electrode2)\n",
    "\n",
    "    df_investigate = pd.DataFrame({    'single':single,\n",
    "                                   'single1':single1,\n",
    "                                   'single2':single2,\n",
    "                                       'double':double, \n",
    "\n",
    "                                       'subject':lst_subject,\n",
    "                                   'electrode_pair':electrode_pair,\n",
    "                                   'amp':amp,\n",
    "                                   'freq':freq\n",
    "                                      })\n",
    "    for subj in ['12-005', '51-009', '52-001']:\n",
    "        df_investigate_temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "        filename = subj + label_list[label] \n",
    "        df_investigate_temp.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')\n",
    "    filename = label_list[label]\n",
    "    df_investigate.to_csv('/home/yuchen/shapes/notebooks/' + filename + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'phos_num'\n",
    "df_investigate[['single','double','subject','electrode_pair','amp','freq']].to_csv('/home/yuchen/' + name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62464a-ef94-4aac-8e37-952189b00fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in ['12-005','51-009','52-001','AllSubjects']:\n",
    "    temp = df_investigate[df_investigate.subject == subj].reset_index(drop=True)\n",
    "    if subj == 'AllSubjects':\n",
    "        temp = df_investigate\n",
    "    X = temp[['single']]\n",
    "    y = temp.double\n",
    "    est = sm.OLS(y, X)\n",
    "#     X2 = sm.add_constant(X)\n",
    "#     est = sm.OLS(y, X2)\n",
    "    est2 = est.fit()\n",
    "    print(est2.pvalues)\n",
    "    \n",
    "#     print('subject: ' + subj)\n",
    "#     print(est2.summary())\n",
    "#     print('\\ncoefficient with more digits: ')\n",
    "#     print(est2.params)\n",
    "#     print('\\npartial correlation: ')\n",
    "#     print(temp[['single','double']].corr())\n",
    "#     print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77813612-ce58-4bfe-abf2-57920c2d8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.ttest_ind(df1.double, df2.double, equal_var=False, alternative='two-sided')\n",
    "# no difference between sequential stimulation and simultaneous stimulation in terms of phosphene numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4936ca-3d9d-49e7-b9be-b5146b8316a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In sequential stimulation\n",
    "temp1 = df1[(df1.same_side == 0) & (df1.distance)]\n",
    "temp2 = df1[df1.same_side == 1]\n",
    "print(temp1.distance.mean())\n",
    "print(temp2.distance.mean())\n",
    "stats.ttest_ind(temp1.double, temp2.double, equal_var=False, alternative='greater')\n",
    "# Electrodes on different side of the raphe are more likely to produce multiple phosphenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf9f2c-117b-4bf1-911d-193776a2b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In simultaneous stimulation\n",
    "temp1 = df2[df2.same_side == 0]\n",
    "temp2 = df2[df2.same_side == 1]\n",
    "print(temp1.distance.mean())\n",
    "print(temp2.distance.mean())\n",
    "stats.ttest_ind(temp1.double, temp2.double, equal_var=False, alternative='greater')\n",
    "# Electrodes on different side of the raphe are more likely to produce multiple phosphenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf071d0-8fa7-4122-970e-25f617ab9f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
